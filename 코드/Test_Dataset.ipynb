{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "from Dataset.Embedding_Dataset import Embedding_Dataset\n",
    "from Model.Embedding import Embedding\n",
    "\n",
    "from Dataset.LSTM_Dataset import LSTM_Dataset\n",
    "from Model.LSTM import LSTM\n",
    "\n",
    "from Dataset.Attention_Dataset import Attention_Dataset\n",
    "from Model.Attention import LSTMSeq2Seq\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device('cpu') # CPU\n",
    "# DEVICE = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu') # 맥\n",
    "# DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') # 윈도우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_lr = 0.0001\n",
    "embedding_batch = 512\n",
    "embedding_epochs = 150\n",
    "encoder_dim_1 = 256\n",
    "encoder_dim_2 = 512\n",
    "embedding_dim = 1024\n",
    "decoder_dim_1 = 512\n",
    "decoder_dim_2 = 256\n",
    "\n",
    "lstm_lr = 0.01\n",
    "lstm_batch = 1\n",
    "lstm_epochs = 50\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "window_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "connection_info = \"host=localhost dbname=postgres user=postgres password=hd219833 port=5432\"\n",
    "conn = psycopg2.connect(connection_info)\n",
    "table_1_query = '''\n",
    "    SELECT * FROM building\n",
    "    '''\n",
    "table_2_query = '''\n",
    "    SELECT * FROM economy\n",
    "    '''\n",
    "table_3_query = '''\n",
    "    SELECT * FROM building_price\n",
    "    '''\n",
    "table_1 = pd.read_sql(table_1_query,conn) \n",
    "table_2 = pd.read_sql(table_2_query,conn)\n",
    "table_3 = pd.read_sql(table_3_query,conn) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_merge = pd.merge(table_1, table_3, how='left', on='aid')\n",
    "table_merge = pd.merge(table_merge, table_2, how='left', on='did')\n",
    "\n",
    "apartment = table_merge[[cols for cols in table_merge.columns if cols not in ['aid','location','name','did','year','month','call_rate','m2','price']]]\n",
    "economy = table_merge[['call_rate','m2']]\n",
    "price = table_merge[['price']]\n",
    "\n",
    "apartment_tensor = torch.FloatTensor(apartment.values)\n",
    "economy_tensor = torch.FloatTensor(economy.values)\n",
    "price_tensor = torch.FloatTensor(price.values)\n",
    "\n",
    "input_tensor = torch.cat((apartment_tensor, economy_tensor), dim=1)\n",
    "output_tensor = price_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../데이터/Checkpoint/embedding_train_0.8_lr_0.0001_batch_512_epochs_150_e1_256_e2_256_emb_1024_d1512_d2_256.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Embedding' object has no attribute 'encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(encoder_input_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 18\u001b[0m         apartment_complex_embedding_vector \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencoder(encoder_input_tensor[i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     19\u001b[0m         apartment_complex_embedding_matrix[i] \u001b[38;5;241m=\u001b[39m apartment_complex_embedding_vector\n\u001b[1;32m     20\u001b[0m apartment_complex_embedding_matrix_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(apartment_complex_embedding_matrix)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Embedding' object has no attribute 'encoder'"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "apartment_complexes_embedding_matrix_with_window_size = []\n",
    "apartment_complexes_price_with_window_size = []\n",
    "\n",
    "apartment_complexes_location = table_1['location']\n",
    "apartment_complexes_name = table_1['name']\n",
    "for apartment_complex_location, apartment_complex_name in zip(apartment_complexes_location, apartment_complexes_name):\n",
    "    apartment_complex_values = table_1[(table_1['name'] == apartment_complex_name) * (table_1['location'] == apartment_complex_location)][[cols for cols in table_1.columns if cols not in ['aid','location','name']]].values\n",
    "    apartment_complex_tensor = torch.FloatTensor(apartment_complex_values).repeat(204, 1)\n",
    "    economy_values = table_2[['call_rate','m2']].values\n",
    "    economy_tensor = torch.FloatTensor(economy_values)\n",
    "    encoder_input_tensor = torch.cat((apartment_complex_tensor, economy_tensor), dim=1)\n",
    "\n",
    "    apartment_complex_embedding_matrix = np.zeros((encoder_input_tensor.shape[0], embedding_dim))\n",
    "    with torch.no_grad():\n",
    "        for i in range(encoder_input_tensor.shape[0]):\n",
    "            apartment_complex_embedding_vector = model.encoder(encoder_input_tensor[i].unsqueeze(0)).squeeze().numpy()\n",
    "            apartment_complex_embedding_matrix[i] = apartment_complex_embedding_vector\n",
    "    apartment_complex_embedding_matrix_tensor = torch.FloatTensor(apartment_complex_embedding_matrix)\n",
    "\n",
    "    apartment_complex_aid = table_1[(table_1['name'] == apartment_complex_name) * (table_1['location'] == apartment_complex_location)]['aid'].squeeze()\n",
    "    price_values = pd.DataFrame({'did': range(0, 204)}).merge(table_3[table_3['aid'] == apartment_complex_aid][['did','price']], on='did', how='outer').fillna(0).set_index('did').values\n",
    "    price_tensor = torch.FloatTensor(price_values)\n",
    "\n",
    "    for i in range(apartment_complex_embedding_matrix_tensor.shape[0]-window_size):\n",
    "        apartment_complexes_embedding_matrix_with_window_size.append(apartment_complex_embedding_matrix_tensor[i:i+window_size, :])\n",
    "        apartment_complexes_price_with_window_size.append(price_tensor[i+window_size, :])\n",
    "\n",
    "apartment_complexes_embedding_matrix_with_window_size = apartment_complexes_embedding_matrix_with_window_size\n",
    "apartment_complexes_price_with_window_size = apartment_complexes_price_with_window_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../데이터/Checkpoint/embedding_lr_0.01_batch_32_epochs_50_dim_6.pth')\n",
    "\n",
    "max_apartment_complexes = 38 # 최대 단지 개수\n",
    "\n",
    "table_1['dong'] = table_1['location'].apply(lambda x: x.split(' ')[2])\n",
    "dongs = table_1['dong'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dongs_apartment_complexes_embedding_matrixes_with_window_size_num = [] # 단지 개수 # (전체 동 개수 * 199, 1)\n",
    "dongs_apartment_complexes_embedding_matrixes_with_window_size_index = [] # y 값이 있는 단지 index # (전체 동 개수 * 199, ?)\n",
    "dongs_apartment_complexes_embedding_matrixes_with_window_size = [] # (전체 동 개수 * 199, 38, window_size, 6)\n",
    "dongs_apartment_complexes_prices_with_window_size = [] # (전체 동 개수 * 199, 38, 1)\n",
    "\n",
    "for dong in dongs: # 동 마다\n",
    "    # dong_apartment_complexes_embedding_matrixes(동 안의 단지마다 임베팅 matrix 구한 뒤 리스트 형식으로 모으기) 완성 # (동 안의 단지 개수, 204, 6)\n",
    "    dong_apartment_complexes_values = table_1[table_1['dong'] == dong][[cols for cols in table_1.columns if cols not in ['aid','location','name','dong']]].values # 하나의 동 안의 아파트 단지 값들 # (동 안의 단지 개수, 10)\n",
    "    economy_values = table_2[['call_rate','m2']].values # 경제 지표 값들 (204, 2)\n",
    "    economy_tensor = torch.FloatTensor(economy_values) # 경제 지표 텐서 변환\n",
    "\n",
    "    encoder_input_tensors = torch.zeros(dong_apartment_complexes_values.shape[0], 204, 12) # 인코더 입력 텐서들 초기화(인코더 입력 텐서 여러개) # (동 안의 단지 개수, 204(시점), 12)\n",
    "    for i, dong_apartment_complex_values in enumerate(dong_apartment_complexes_values):\n",
    "        dong_apartment_complex_tensor = torch.FloatTensor(dong_apartment_complex_values).repeat(204,1) \n",
    "        encoder_input_tensor = torch.cat((dong_apartment_complex_tensor, economy_tensor), dim=1)\n",
    "        encoder_input_tensors[i] = encoder_input_tensor\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dong_apartment_complexes_embedding_matrixes = torch.zeros(encoder_input_tensors.shape[0], 204, embedding_dim) # (동 안의 단지 개수, 204, 6)\n",
    "        for i in range(encoder_input_tensors.shape[0]): # 동 안의 단지 (204, 6)\n",
    "            apartment_complex_embedding_matrix = torch.zeros(204,embedding_dim) # (204, 6)\n",
    "            for j in range(204): # 시점\n",
    "                apartment_complex_embedding_vector = model.encoder(encoder_input_tensors[i][j].unsqueeze(0)).squeeze() # (6, )\n",
    "                apartment_complex_embedding_matrix[j] = apartment_complex_embedding_vector\n",
    "            dong_apartment_complexes_embedding_matrixes[i] = apartment_complex_embedding_matrix\n",
    "\n",
    "\n",
    "    # dong_apartment_complexes_prices(동 안의 단지마다 가격 구한 뒤 리스트 형식으로 모으기) 완성 # (동 안의 단지 개수, 204, 1)\n",
    "    dong_apartment_complexes_aids = table_1[table_1['dong'] == dong]['aid'].values # (동 안의 단지 개수, )\n",
    "    dong_apartment_complexes_prices = torch.zeros(dong_apartment_complexes_aids.shape[0],204,1) # (동 안의 단지 개수, 204, 1)\n",
    "    for i, dong_apartment_complex_aid in zip(range(dong_apartment_complexes_aids.shape[0]), dong_apartment_complexes_aids): # 동 안의 단지 개수, 동 안의 단지들의 aids\n",
    "        dong_apartment_complexes_prices[i] = torch.from_numpy(pd.DataFrame({'did': range(0, 204)}).merge(table_3[table_3['aid'] == dong_apartment_complex_aid][['did','price']], on='did', how='outer').fillna(0).set_index('did').values) # (204, 1)\n",
    "\n",
    "\n",
    "    # dong_apartment_complexes_embedding_matrixes와 dong_apartment_complexes_prices window_size로 나누기\n",
    "    for i in range(204-window_size): # window_size 고려한 시점(0~199)\n",
    "        dong_apartment_complexes_embedding_matrixes_with_window_size = torch.zeros(max_apartment_complexes, window_size, embedding_dim) # (38, window_size, 6)\n",
    "        dong_apartment_complexes_prices_with_window_size = torch.zeros(max_apartment_complexes, 1) # (38, 1)\n",
    "        for j in range(dong_apartment_complexes_embedding_matrixes.shape[0]): # 동 안의 단지 개수\n",
    "            dong_apartment_complexes_embedding_matrixes_with_window_size[j] = dong_apartment_complexes_embedding_matrixes[j][i:i+window_size,:] # (window_size, 6)\n",
    "            dong_apartment_complexes_prices_with_window_size[j] = dong_apartment_complexes_prices[j][i+window_size,:] # (1, )\n",
    "        dongs_apartment_complexes_embedding_matrixes_with_window_size_num.append(dong_apartment_complexes_embedding_matrixes.shape[0]) # 자연수\n",
    "        dongs_apartment_complexes_embedding_matrixes_with_window_size_index.append(torch.nonzero(dong_apartment_complexes_prices_with_window_size, as_tuple=False)[:, 0]) # (1, )\n",
    "        dongs_apartment_complexes_embedding_matrixes_with_window_size.append(dong_apartment_complexes_embedding_matrixes_with_window_size) # (38, window_size, 6)\n",
    "        dongs_apartment_complexes_prices_with_window_size.append(dong_apartment_complexes_prices_with_window_size) # (38, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
