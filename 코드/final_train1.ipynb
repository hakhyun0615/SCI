{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from Dataset.WindowDataset import WindowDataset\n",
    "\n",
    "from Model.AE import Auto\n",
    "from Model.LSTM import LSTM\n",
    "from Model.LODE2 import ODEVAE\n",
    "\n",
    "from utils import combine_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco = '콜금리'\n",
    "batch_size = 4\n",
    "max_apart_size = 70  # 0~60평 아파트만 돌림\n",
    "real_estate_weighted_average = 0.5\n",
    "input_size = 5 # LSTM input_size\n",
    "hidden_size = 16 # LSTM hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_estimate(x):\n",
    "    vec = np.zeros((max_apart_size))\n",
    "    vec[int(x[0])] = x[1]\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../데이터/merge.csv')\n",
    "df['시점'] = df['계약년월'] + df['계약일']\n",
    "df = df[:100] # //////////////////////////////\n",
    "df['시점'].apply(lambda x : int(x))\n",
    "df['평수'] = df['전용면적(㎡)'].apply(lambda x : x // 3.3058)\n",
    "df['가격'] = df['거래금액(만원)'].apply(lambda x : int(x.replace(',','')))\n",
    "df = df.sort_values(by=['시점'])\n",
    "df['부동산'] = df[['평수','가격']].apply(make_estimate,axis=1)\n",
    "df.reset_index(drop=True)\n",
    "df['경제'] = df[eco]\n",
    "df = df[['시점','부동산','경제']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimhakhyun/Desktop/Git/sci/SCI/코드/Dataset/WindowDataset.py:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:248.)\n",
      "  self.x1 = torch.FloatTensor(X1)\n"
     ]
    }
   ],
   "source": [
    "len_df = len(df)\n",
    "train_len = int(len_df *0.6)\n",
    "val_len = int(len_df * 0.3)\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "train_dataset = WindowDataset(df[:train_len])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "val_dataset = WindowDataset(df[train_len:train_len+val_len])\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "test_dataset = WindowDataset(df[train_len+val_len:])\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 2])\n",
      "torch.Size([2, 5, 1, 70])\n"
     ]
    }
   ],
   "source": [
    "for x1,x2,y1,y2 in train_loader:\n",
    "    print(x1.shape)\n",
    "    print(x2.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 모델\n",
    "\n",
    "model = ODEVAE(2, 64, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# 데이터 & 모델에 device 붙임!!!\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'{device} is available')\n",
    "\n",
    "# model = Model.to(device)\n",
    "\n",
    "# print('작동하는지 실험')\n",
    "# basic_data = torch.rand((1,input_size))\n",
    "# model(basic_data)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "lr = 1e-3\n",
    "num_epochs = 10\n",
    "noise_std = 0.02\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Auto:\n\tsize mismatch for encoder.0.weight: copying a param with shape torch.Size([32, 7]) from checkpoint, the shape in current model is torch.Size([32, 70]).\n\tsize mismatch for decoder.2.weight: copying a param with shape torch.Size([7, 32]) from checkpoint, the shape in current model is torch.Size([70, 32]).\n\tsize mismatch for decoder.2.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([70]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m economy_embedding_model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mCheckpoint/economic_best_model.pth\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      4\u001b[0m real_estate_embedding_model \u001b[39m=\u001b[39m Auto(max_apart_size)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 5\u001b[0m real_estate_embedding_model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mCheckpoint/embedding_best_model.pth\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Auto:\n\tsize mismatch for encoder.0.weight: copying a param with shape torch.Size([32, 7]) from checkpoint, the shape in current model is torch.Size([32, 70]).\n\tsize mismatch for decoder.2.weight: copying a param with shape torch.Size([7, 32]) from checkpoint, the shape in current model is torch.Size([70, 32]).\n\tsize mismatch for decoder.2.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([70])."
     ]
    }
   ],
   "source": [
    "economy_embedding_model = LSTM(input_size,hidden_size).to(device)\n",
    "economy_embedding_model.load_state_dict(torch.load('Checkpoint/economic_best_model.pth'))\n",
    "\n",
    "real_estate_embedding_model = Auto(max_apart_size).to(device)\n",
    "real_estate_embedding_model.load_state_dict(torch.load('Checkpoint/embedding_best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6234, 0.0333, 0.9214, 0.7519, 0.8305],\n",
       "        [0.6660, 0.7309, 0.4756, 0.0741, 0.2760],\n",
       "        [0.7328, 0.8379, 0.7091, 0.5508, 0.4279],\n",
       "        [0.8611, 0.5838, 0.0804, 0.2475, 0.6017],\n",
       "        [0.2672, 0.2526, 0.6937, 0.8916, 0.1437]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_data = torch.rand((5,input_size))\n",
    "time_data = [20180103,20180904,20180906,20181011,20190101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print('epoch : {}'.format(epoch))\n",
    "    running_loss = 0.0\n",
    "    num = 0\n",
    "    print(\"train\")\n",
    "    model.train()\n",
    "    for x1, x2, y1, y2 in train_loader:\n",
    "        x1, x2 = x1.to(device), x2.to(device) # x1: [시점, 경제], x2: 부동산\n",
    "        y1, y2 = y1.to(device), y2.to(device)\n",
    "\n",
    "        # 경제 데이터\n",
    "        eco_emb = economy_embedding_model(x1[1])\n",
    "        # 부동산 데이터\n",
    "        real_est_emb = real_estate_embedding_model(x2)\n",
    "        \n",
    "        final_emb = combine_tensors(real_est_emb, eco_emb, real_estate_weighted_average, 'sum')\n",
    "        ##########################\n",
    "        # 모델에 x[0], final_emb 가지고 ODE 학습하기!!!!\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_p, z, z_mean, z_log_var = model(final_emb, x1[0])\n",
    "        kl_loss = -0.5 * torch.sum(1 + z_log_var - z_mean**2 - torch.exp(z_log_var), -1)\n",
    "        loss = 0.5 * ((final_emb-x_p)**2).sum(-1).sum(0) / noise_std**2 + kl_loss\n",
    "        loss = torch.mean(loss)\n",
    "       \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
