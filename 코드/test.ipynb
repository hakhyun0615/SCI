{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "from Dataset.Embedding_Dataset import Embedding_Dataset\n",
    "from Model.Embedding import Embedding\n",
    "\n",
    "from Dataset.Apartment_Complex_Dataset import Apartment_Complex_Dataset\n",
    "from Model.LSTM import LSTM\n",
    "from Model.GRU import GRU\n",
    "from Model.Transformer import Transformer\n",
    "from Model.Informer import Informer\n",
    "from Model.Pyraformer import Pyraformer\n",
    "from Model.N_BEATS import NBeats\n",
    "from Model.NLinear import NLinear\n",
    "\n",
    "from Dataset.District_Dataset import District_Dataset\n",
    "from Model.LSTM_Attention import LSTMAttention\n",
    "from Model.GRU_Attention import GRUAttention\n",
    "from Model.Transformer_Attention import TransformerAttention\n",
    "\n",
    "from utils import RMSE, rmse, mse, mae, save_train_val_losses\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# connection_info = \"host=localhost dbname=postgres user=postgres password=hd219833 port=5432\"\n",
    "# conn = psycopg2.connect(connection_info)\n",
    "# table_1_query = '''\n",
    "#     SELECT * FROM building\n",
    "#     '''\n",
    "# table_2_query = '''\n",
    "#     SELECT * FROM economy\n",
    "#     '''\n",
    "# table_3_query = '''\n",
    "#     SELECT * FROM building_price\n",
    "#     '''\n",
    "# table_1 = pd.read_sql(table_1_query,conn) \n",
    "# table_2 = pd.read_sql(table_2_query,conn)\n",
    "# table_3 = pd.read_sql(table_3_query,conn) \n",
    "\n",
    "table_1 = pd.read_csv('../데이터/Table/table_1.csv') \n",
    "table_2 = pd.read_csv('../데이터/Table/table_2.csv') \n",
    "table_3 = pd.read_csv('../데이터/Table/table_3.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "lr = 1e-4\n",
    "batch = 64\n",
    "hidden_dim = 1024\n",
    "sub = True\n",
    "embedding_dim = 1024\n",
    "window_size = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = torch.load(\"../데이터/Checkpoint/embedding/default/embedding_lr_0.0001_batch_64_sub_True_emb_1024_ws_12_epochs_13.pth\", map_location=DEVICE)\n",
    "dataset = District_Dataset(embedding_model, table_1, table_2, table_3, embedding_dim, window_size, sub, DEVICE)\n",
    "dataset_length = len(dataset)\n",
    "train_size = int(train_ratio * dataset_length)\n",
    "# train_indices = range(0, train_size)\n",
    "val_size = int(val_ratio * dataset_length)\n",
    "# val_indices = range(train_size, train_size + val_size)\n",
    "test_size = int(test_ratio * dataset_length)\n",
    "test_indices = range(train_size + val_size, dataset_length)\n",
    "# train_dataset = Subset(dataset, train_indices)\n",
    "# val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=batch, shuffle=False, drop_last=True)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=batch, shuffle=False, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "# model = torch.load(\"../데이터/Checkpoint/lstm/default/lstm_lr_0.0001_batch_64_hid_1024_sub_True_emb_1024_ws_12_epochs_10.pth\", map_location=DEVICE)\n",
    "\n",
    "# GRU\n",
    "# model = torch.load(\"../데이터/Checkpoint/gru/default/gru_lr_0.0001_batch_64_hid_1024_sub_True_emb_1024_ws_12_epochs_9.pth\", map_location=DEVICE)\n",
    "\n",
    "# transformer\n",
    "# model = torch.load(\"../데이터/Checkpoint/transformer/default/transformer_lr_0.0001_batch_64_sub_True_emb_1024_ws_12_epochs_15.pth\", map_location=DEVICE)\n",
    "\n",
    "# LSTM attention\n",
    "# model = torch.load(\"../데이터/Checkpoint/lstm/attention/lstm_attention_lr_0.0001_batch_64_sub_True_emb_1024_ws_12_epochs_8.pth\", map_location=DEVICE)\n",
    "\n",
    "# GRU attention\n",
    "# model = torch.load(\"../데이터/Checkpoint/gru/attention/gru_attention_lr_0.0001_batch_64_sub_True_emb_1024_ws_12_epochs_4.pth\", map_location=DEVICE)\n",
    "\n",
    "# transformer attention\n",
    "# model = torch.load(\"../데이터/Checkpoint/transformer/attention/default/transformer_attention_lr_0.0001_batch_64_sub_True_emb_1024_ws_12_epochs_5.pth\", map_location=DEVICE)\n",
    "\n",
    "# Informer\n",
    "model = torch.load(f'../데이터/Checkpoint/informer/informer_lr_{lr}_batch_{batch}_sub_{sub}_emb_{embedding_dim}_ws_{window_size}_epochs_16.pth', map_location=DEVICE)\n",
    "\n",
    "# Pyraformer\n",
    "# model = torch.load(f'../데이터/Checkpoint/pyraformer/pyraformer_lr_{lr}_batch_{batch}_sub_{sub}_emb_{embedding_dim}_ws_{window_size}_epochs_{epoch+1}.pth', map_location=DEVICE)\n",
    "\n",
    "\n",
    "# N_BEATS\n",
    "# model = torch.load(f'../데이터/Checkpoint/n_beats/n_beats_lr_{lr}_batch_{batch}_sub_{sub}_emb_{embedding_dim}_ws_{window_size}_epochs_{epoch+1}.pth', map_location=DEVICE)\n",
    "\n",
    "# NLinear\n",
    "# model = torch.load(f'../데이터/Checkpoint/nlinear/nlinear_lr_{lr}_batch_{batch}_sub_{sub}_emb_{embedding_dim}_ws_{window_size}_epochs_{epoch+1}.pth', map_location=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         trg \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m anw:\n\u001b[0;32m     20\u001b[0m             \u001b[38;5;66;03m# LSTM\u001b[39;00m\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;66;03m# output, _, _ = model(src)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \n\u001b[0;32m     33\u001b[0m \t\t\t\u001b[38;5;66;03m# informer\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m             output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m     36\u001b[0m \t\t\t\u001b[38;5;66;03m# pyraformer\u001b[39;00m\n\u001b[0;32m     37\u001b[0m             \u001b[38;5;66;03m# output = model(src.unsqueeze(0))[:, -1, :]\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m \t\t\t\u001b[38;5;66;03m# nlinear\u001b[39;00m\n\u001b[0;32m     43\u001b[0m             \u001b[38;5;66;03m# output = model(src.unsqueeze(0))[:, -1, :]\u001b[39;00m\n\u001b[0;32m     45\u001b[0m             test_outputs\u001b[38;5;241m.\u001b[39mappend(output\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()) \u001b[38;5;66;03m# test_outputs.append(output[index])\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\USER\\Desktop\\Git\\sci\\SCI\\코드\\Model\\Informer.py:94\u001b[0m, in \u001b[0;36mInformer.forward\u001b[1;34m(self, x_enc)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_enc):\n\u001b[0;32m     93\u001b[0m     enc_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_embedding(x_enc)\n\u001b[1;32m---> 94\u001b[0m     enc_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     dec_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojection(enc_out)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dec_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_len:, :]\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\USER\\Desktop\\Git\\sci\\SCI\\코드\\Model\\Informer.py:62\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x, attn_mask)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, attn_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attn_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_layers:\n\u001b[1;32m---> 62\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mattn_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\USER\\Desktop\\Git\\sci\\SCI\\코드\\Model\\Informer.py:46\u001b[0m, in \u001b[0;36mEncoderLayer.forward\u001b[1;34m(self, x, attn_mask)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, attn_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 46\u001b[0m     new_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(new_x)\n\u001b[0;32m     48\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\USER\\Desktop\\Git\\sci\\SCI\\코드\\Model\\Informer.py:16\u001b[0m, in \u001b[0;36mProbAttention.forward\u001b[1;34m(self, queries, keys, values, attn_mask)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, queries, keys, values, attn_mask):\n\u001b[1;32m---> 16\u001b[0m     B, L, E \u001b[38;5;241m=\u001b[39m queries\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     17\u001b[0m     _, S, _ \u001b[38;5;241m=\u001b[39m keys\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     19\u001b[0m     scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39mmath\u001b[38;5;241m.\u001b[39msqrt(E)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_rmses = []\n",
    "test_mses = []\n",
    "test_maes = []\n",
    "\n",
    "test_outputs = []\n",
    "test_trgs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        src = data[0][0].to(DEVICE)\n",
    "        max_len = data[1][0].to(DEVICE)\n",
    "        try:\n",
    "            anw = torch.nonzero(data[2][0]).to(DEVICE)[0]\n",
    "        except:\n",
    "            continue\n",
    "        trg = data[3][0].to(DEVICE)\n",
    "\n",
    "        for index in anw:\n",
    "            # LSTM\n",
    "            # output, _, _ = model(src)\n",
    "            \n",
    "            # GRU\n",
    "            # output, _ = model(src)\n",
    "            \n",
    "            # nlinear\n",
    "            # output, _ = model(src)\n",
    "            \n",
    "            # transformer\n",
    "            # src_mask = model.generate_square_subsequent_mask(src.shape[1]).to(src.device)\n",
    "            # output, _ = model(src, src_mask)\n",
    "            \n",
    "\t\t\t# informer\n",
    "            output = model(src.unsqueeze(0))[:, -1, :]\n",
    "            \n",
    "\t\t\t# pyraformer\n",
    "            # output = model(src.unsqueeze(0))[:, -1, :]\n",
    "\n",
    "\t\t\t# n_beats\n",
    "            # output = model(src[index].view(1, -1))\n",
    "            \n",
    "\t\t\t# nlinear\n",
    "            # output = model(src.unsqueeze(0))[:, -1, :]\n",
    "\n",
    "            test_outputs.append(output.squeeze().cpu()) # test_outputs.append(output[index])\n",
    "            test_trgs.append(trg[index].cpu())\n",
    "\n",
    "            # attention\n",
    "            # output = model(src, index, max_len)\n",
    "\n",
    "            # test_outputs.append(output)\n",
    "            # test_trgs.append(trg[index])\n",
    "\n",
    "save_path = f'../데이터/Checkpoint/transformer/attention/default/transformer_attention_lr_{lr}_batch_{batch}_sub_{sub}_emb_{embedding_dim}_ws_{window_size}_epochs_{5}'\n",
    "with open(f'{save_path}_test_rmses.txt', 'w') as f:\n",
    "    for item in test_rmses:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "with open(f'{save_path}_test_mses.txt', 'w') as f:\n",
    "    for item in test_mses:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "with open(f'{save_path}_test_maes.txt', 'w') as f:\n",
    "    for item in test_maes:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "test_outputs = torch.stack(test_outputs) # test_outputs = torch.FloatTensor(test_outputs)\n",
    "test_trgs = torch.stack(test_trgs) # test_trgs = torch.FloatTensor(test_trgs)  \n",
    "\n",
    "test_rmse = rmse(test_outputs, test_trgs)\n",
    "test_mse = mse(test_outputs, test_trgs)\n",
    "test_mae = mae(test_outputs, test_trgs)\n",
    "\n",
    "print(f'Test RMSE: {test_rmse:.4f}')\n",
    "print(f'Test MSE: {test_mse:.4f}')\n",
    "print(f'Test MAE: {test_mae:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = torch.load('../데이터/Checkpoint/embedding/default/embedding_lr_0.0001_batch_64_sub_True_emb_1024_ws_12_epochs_13.pth', map_location=DEVICE)\n",
    "dataset = Apartment_Complex_Dataset(embedding_model, table_1, table_2, table_3, embedding_dim, window_size, 'ML', DEVICE)\n",
    "dataset_length = len(dataset)\n",
    "train_size = int(train_ratio * dataset_length)\n",
    "# train_indices = range(0, train_size)\n",
    "val_size = int(val_ratio * dataset_length)\n",
    "# val_indices = range(train_size, train_size + val_size)\n",
    "test_size = int(test_ratio * dataset_length)\n",
    "test_indices = range(train_size + val_size, dataset_length)\n",
    "# train_dataset = Subset(dataset, train_indices)\n",
    "# val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=batch, shuffle=False, drop_last=True)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=batch, shuffle=False, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm\n",
    "model = joblib.load(f'../데이터/Checkpoint/lightgbm/lightgbm_batch_64_ws_12.pkl')\n",
    "\n",
    "# catboost\n",
    "# model = joblib.load(f'../데이터/Checkpoint/catboost/catboost_batch_64_ws_12.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_pred, y_true):\n",
    "      mse = np.mean((y_true - y_pred) ** 2)\n",
    "      return np.sqrt(mse)\n",
    "\n",
    "def mse(y_pred, y_true):\n",
    "      return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def mae(y_pred, y_true):\n",
    "      return np.mean(np.abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 20.7914\n",
      "Test MSE: 432.2820\n",
      "Test MAE: 20.7664\n"
     ]
    }
   ],
   "source": [
    "test_rmses = []\n",
    "test_mses = []\n",
    "test_maes = []\n",
    "\n",
    "test_outputs = []\n",
    "test_trgs = []\n",
    "\n",
    "for data in test_dataloader:\n",
    "    X, y = data[0].squeeze().cpu().numpy(), data[1].squeeze().cpu().numpy()\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    test_outputs.append(y_pred)\n",
    "    test_trgs.append(y)\n",
    "\n",
    "save_path = f'../데이터/Checkpoint/lightgbm/lightgbm_batch_{batch}_ws_{window_size}'\n",
    "with open(f'{save_path}_test_rmses.txt', 'w') as f:\n",
    "    for item in test_rmses:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "with open(f'{save_path}_test_mses.txt', 'w') as f:\n",
    "    for item in test_mses:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "with open(f'{save_path}_test_maes.txt', 'w') as f:\n",
    "    for item in test_maes:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "test_rmse = rmse(y_pred, y)\n",
    "test_mse = mse(y_pred, y)\n",
    "test_mae = mae(y_pred, y)\n",
    "\n",
    "print(f'Test RMSE: {test_rmse:.4f}')\n",
    "print(f'Test MSE: {test_mse:.4f}')\n",
    "print(f'Test MAE: {test_mae:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
