{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "from Dataset.Embedding_Dataset import Embedding_Dataset\n",
    "from Model.Embedding import Embedding\n",
    "\n",
    "from Dataset.Apartment_Complex_Dataset import Apartment_Complex_Dataset\n",
    "from Model.LSTM import LSTM\n",
    "from Model.GRU import GRU\n",
    "from Model.NLinear import NLinear\n",
    "from Model.Transformer import Transformer2\n",
    "\n",
    "from Dataset.Dong_Dataset import Dong_Dataset\n",
    "from Model.LSTM_Attention_E2E import LSTMSeq2Seq\n",
    "from Model.LSTM_Attention import LSTMAttention\n",
    "from Model.GRU_Attention import GRUAttention\n",
    "from Model.Transformer_Attention_E2E import TransformerSeq2Seq\n",
    "from Model.Transformer_Attention import TransformerAttention\n",
    "from Model.NLinear_Attention import NLinearAttention\n",
    "\n",
    "from utils import *\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 1024\n",
    "window_size = 10\n",
    "batch_size = 1\n",
    "\n",
    "ml_batch = 128\n",
    "ml_estimators = 150\n",
    "ml_window_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_1 = pd.read_csv('../데이터/Table/test_table_1.csv') \n",
    "table_2 = pd.read_csv('../데이터/Table/test_table_2.csv') \n",
    "table_3 = pd.read_csv('../데이터/Table/test_table_3.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_12_dim\n",
    "# dataset = Dong_Dataset('None', table_1, table_2, table_3, 'None', window_size, 'TEST', DEVICE)\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "# emb_1024_dim\n",
    "model = torch.load('../데이터/Checkpoint/emb_1024_dim/embedding_tr_0.8_lr_1e-05_wd_0_batch_128_epochs_131_e1_128_e2_128_e3_512_emb_1024_d1_512_d2_256_d3_128.pth', map_location=torch.device('cpu'))\n",
    "dataset = Dong_Dataset(model, table_1, table_2, table_3, embedding_dim, window_size, 'TEST', DEVICE)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "# model = torch.load(\"../데이터/Checkpoint/concat_12_dim/lstm_tr_0.8_lr_1e-05_wd_0_batch_128_epochs_124_hdim_256_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "# model = torch.load(\"../데이터/Checkpoint/lstm_tr_0.8_lr_1e-06_wd_0_batch_128_epochs_134_hdim_256_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "# GRU\n",
    "# model = torch.load(\"../데이터/Checkpoint/concat_12_dim/gru_tr_0.8_lr_1e-05_wd_0_batch_128_epochs_321_hdim_256_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "# model = torch.load(\"../데이터/Checkpoint/gru_tr_0.8_lr_1e-06_wd_0_batch_128_epochs_164_hdim_256_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "# nlinear\n",
    "# model = torch.load(\"../데이터/Checkpoint/concat_12_dim/nlinear_tr_0.8_lr_1e-05_wd_0_batch_128_epochs_118_emb_12_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "# transformer\n",
    "# model = torch.load(\"../데이터/Checkpoint/concat_12_dim/transformer_tr_0.8_lr_1e-05_wd_0_batch_1_epochs_63_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "model = torch.load(\"../데이터/Checkpoint/transformer_tr_0.8_lr_1e-06_wd_0_batch_1_epochs_9_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "# LSTM attention\n",
    "# model = torch.load(\"../데이터/Checkpoint/concat_12_dim/lstm_att_tr_0.8_lr_1e-05_wd_0_batch_1_epochs_4_hdim_256_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "# model = torch.load(\"../데이터/Checkpoint/lstm_att_tr_0.8_lr_1e-06_wd_0_batch_1_epochs_4_hdim_256_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "# GRU attention\n",
    "# model = torch.load(\"../데이터/Checkpoint/concat_12_dim/gru_att_tr_0.8_lr_1e-05_wd_0_batch_1_epochs_4_hdim_256_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "# model = torch.load(\"../데이터/Checkpoint/gru_att_tr_0.8_lr_1e-06_wd_0_batch_1_epochs_4_hdim_256_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "# NLinear attention\n",
    "# model = torch.load(\"../데이터/Checkpoint/concat_12_dim/nlinear_att_tr_0.8_lr_1e-05_wd_0_batch_1_epochs_6.pth\", map_location=torch.device('cpu'))\n",
    "# model = torch.load(\"../데이터/Checkpoint/emb_1024_dim/\", map_location=torch.device('cpu'))\n",
    "\n",
    "# Transformer attention\n",
    "# model = torch.load(\"../데이터/Checkpoint/concat_12_dim/transformer_att_tr_0.8_lr_1e-05_wd_0_batch_1_epochs_7_hdim_12_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "# model = torch.load(\"../데이터/Checkpoint/transformer_att_tr_0.8_lr_1e-05_wd_0_batch_1_epochs_15_hdim_1024_ws_10.pth\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE Loss: 2.5371\n",
      "Test MAE Loss: 2.5371\n"
     ]
    }
   ],
   "source": [
    "RMSE_criterion = RMSE()\n",
    "MAE_criterion = MAE()\n",
    "\n",
    "count = 0\n",
    "RMSE_total_loss = 0\n",
    "MAE_total_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        src = batch[0][0].to(DEVICE)\n",
    "        max_len = batch[1][0].to(DEVICE)\n",
    "        anw = batch[2][0]\n",
    "        trg = batch[3][0].to(DEVICE)\n",
    "        \n",
    "        if len(anw) == 0:\n",
    "            continue\n",
    "        \n",
    "        RMSE_epoch_loss = 0\n",
    "        MAE_epoch_loss = 0\n",
    "        count += anw.shape[0]\n",
    "\n",
    "        for index in anw:\n",
    "            index.to(DEVICE)\n",
    "            # LSTM\n",
    "            # output, _, _ = model(src)\n",
    "            \n",
    "            # GRU\n",
    "            # output, _ = model(src)\n",
    "            \n",
    "            # nlinear\n",
    "            # output, _ = model(src)\n",
    "            \n",
    "            # transformer\n",
    "            src_mask = model.generate_square_subsequent_mask(src.shape[1]).to(src.device)\n",
    "            output, _ = model(src, src_mask)\n",
    "            \n",
    "            RMSE_loss = RMSE_criterion(output[index], trg[index])\n",
    "            MAE_loss = MAE_criterion(output[index], trg[index])\n",
    "            \n",
    "            # attention 계열\n",
    "            # output = model(src, index, max_len)\n",
    "            # RMSE_loss = RMSE_criterion(output, trg[index])\n",
    "            # MAE_loss = MAE_criterion(output, trg[index])\n",
    "            \n",
    "        RMSE_total_loss += RMSE_loss\n",
    "        MAE_total_loss += MAE_loss\n",
    "\n",
    "    print(f'Test RMSE Loss: {RMSE_total_loss/count:.4f}')\n",
    "    print(f'Test MAE Loss: {MAE_total_loss/count:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_12_dim\n",
    "dataset = Apartment_Complex_Dataset('None', table_1, table_2, table_3, 'None', ml_window_size, 'ML', 'TEST', DEVICE)\n",
    "dataloader = DataLoader(dataset, batch_size=ml_batch, shuffle=False, drop_last=True)\n",
    "\n",
    "# emb_1024_dim\n",
    "# model = torch.load('../데이터/Checkpoint/embedding_tr_0.8_lr_1e-05_wd_0_batch_128_epochs_131_e1_128_e2_128_e3_512_emb_1024_d1_512_d2_256_d3_128.pth', map_location=torch.device('cpu'))\n",
    "# dataset = Apartment_Complex_Dataset(model, table_1, table_2, table_3, embedding_dim, ml_window_size, 'ML', 'TEST', DEVICE)\n",
    "# dataloader = DataLoader(dataset, batch_size=ml_batch, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm\n",
    "# model =  joblib.load('../데이터/Checkpoint/concat_12_dim/lightgbm_tr_0.8_batch_128_estimators_150_ws_10.pkl')\n",
    "# catboost\n",
    "model =  joblib.load('../데이터/Checkpoint/concat_12_dim/catboost_tr_0.8_batch_128_estimators_150_ws_10.pkl')\n",
    "\n",
    "RMSE_total_loss = 0\n",
    "MAE_total_loss = 0\n",
    "\n",
    "for i, data in enumerate(dataloader):\n",
    "    X, y = data[0].squeeze().cpu().numpy(), data[1].squeeze().cpu().numpy()\n",
    "    y_pred = model.predict(X)\n",
    "    RMSE_loss = MSE(y, y_pred)\n",
    "    RMSE_total_loss += RMSE_loss/len(dataloader)\n",
    "    MAE_loss = MAE(y, y_pred)\n",
    "    MAE_total_loss += MAE_loss/len(dataloader)\n",
    "\n",
    "print(f'Test RMSE Loss: {RMSE_total_loss:.4f}')\n",
    "print(f'Test MAE Loss: {MAE_total_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
