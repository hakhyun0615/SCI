{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "from Dataset.Embedding_Dataset import Embedding_Dataset\n",
    "from Model.Embedding import Embedding\n",
    "\n",
    "from Dataset.Apartment_Complex_Dataset import Apartment_Complex_Dataset\n",
    "from Model.LSTM import LSTM\n",
    "from Model.GRU import GRU\n",
    "from Model.Transformer import Transformer\n",
    "\n",
    "from Dataset.Dong_Dataset import Dong_Dataset\n",
    "from Model.LSTM_Attention import LSTMAttention\n",
    "from Model.GRU_Attention import GRUAttention\n",
    "from Model.Transformer_Attention import TransformerAttention\n",
    "\n",
    "from utils import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def MAPE(y_test, y_pred):\n",
    "    return torch.mean(torch.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 1024\n",
    "window_size = 10\n",
    "batch_size = 1\n",
    "\n",
    "ml_batch = 128\n",
    "ml_estimators = 150\n",
    "ml_window_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_1 = pd.read_csv('../데이터/Table/test_table_1.csv') \n",
    "table_2 = pd.read_csv('../데이터/Table/test_table_2.csv') \n",
    "table_3 = pd.read_csv('../데이터/Table/test_table_3.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1874"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_merge = pd.merge(table_1, table_3, how='left', on='aid')\n",
    "table_merge = pd.merge(table_merge, table_2, how='left', on='did')\n",
    "len(table_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_12_dim\n",
    "# dataset = Dong_Dataset('None', table_1, table_2, table_3, 'None', window_size, 'TEST', DEVICE)\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "# emb_1024_dim\n",
    "model = torch.load('../데이터/Checkpoint/embedding_tr_0.8_lr_0.0001_wd_0_batch_128_epochs_6_e1_128_e2_128_e3_512_emb_1024_d1_512_d2_256_d3_128.pth', map_location=torch.device('cpu'))\n",
    "dataset = Dong_Dataset(model, table_1, table_2, table_3, embedding_dim, window_size, 'TEST', DEVICE)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "# model = torch.load(\"../데이터/Checkpoint/concat_12_dim/lstm_tr_0.8_lr_1e-05_wd_0_batch_128_epochs_124_hdim_256_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "# model = torch.load(\"../데이터/Checkpoint/lstm_tr_0.8_lr_0.0001_wd_0_batch_128_epochs_64_hdim_256_ws_3.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "# GRU\n",
    "# model = torch.load(\"../데이터/Checkpoint/concat_12_dim/gru_tr_0.8_lr_1e-05_wd_0_batch_128_epochs_321_hdim_256_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "# model = torch.load(\"../데이터/Checkpoint/gru_tr_0.8_lr_0.0001_wd_0_batch_128_epochs_71_hdim_256_ws_3.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "# nlinear\n",
    "# model = torch.load(\"../데이터/Checkpoint/concat_12_dim/nlinear_tr_0.8_lr_1e-05_wd_0_batch_128_epochs_118_emb_12_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "# transformer\n",
    "# model = torch.load(\"../데이터/Checkpoint/concat_12_dim/transformer_tr_0.8_lr_1e-05_wd_0_batch_1_epochs_63_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "# model = torch.load(\"../데이터/Checkpoint/transformer_tr_0.8_lr_0.0001_wd_0_batch_128_epochs_5_ws_3.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "# LSTM attention\n",
    "# model = torch.load(\"../데이터/Checkpoint/concat_12_dim/lstm_att_tr_0.8_lr_1e-05_wd_0_batch_1_epochs_4_hdim_256_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "# model = torch.load(\"../데이터/Checkpoint/dong/1024_dim/10_ws/lstm_att_tr_0.8_lr_0.0001_wd_0_batch_1_epochs_34_hdim_256_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "# GRU attention\n",
    "# model = torch.load(\"../데이터/Checkpoint/concat_12_dim/gru_att_tr_0.8_lr_1e-05_wd_0_batch_1_epochs_4_hdim_256_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "# model = torch.load(\"../데이터/Checkpoint/gru_att_tr_0.8_lr_1e-06_wd_0_batch_1_epochs_4_hdim_256_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "# NLinear attention\n",
    "# model = torch.load(\"../데이터/Checkpoint/concat_12_dim/nlinear_att_tr_0.8_lr_1e-05_wd_0_batch_1_epochs_6.pth\", map_location=torch.device('cpu'))\n",
    "# model = torch.load(\"../데이터/Checkpoint/emb_1024_dim/\", map_location=torch.device('cpu'))\n",
    "\n",
    "# Transformer attention\n",
    "# model = torch.load(\"../데이터/Checkpoint/concat_12_dim/transformer_att_tr_0.8_lr_1e-05_wd_0_batch_1_epochs_7_hdim_12_ws_10.pth\", map_location=torch.device('cpu'))\n",
    "# model = torch.load(\"../데이터/Checkpoint/dong/1024_dim/10_ws/transformer_att_tr_0.8_lr_0.0001_wd_0_batch_1_epochs_11_hdim_1024_ws_10.pth\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE Loss: 1.8382\n",
      "Test MSE Loss: 15.9428\n",
      "Test MAPE Loss: 23.2572\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "RMSE_total_loss = 0\n",
    "MSE_total_loss = 0\n",
    "MAPE_total_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        src = batch[0][0].to(DEVICE)\n",
    "        max_len = batch[1][0].to(DEVICE)\n",
    "        anw = batch[2][0]\n",
    "        trg = batch[3][0].to(DEVICE)\n",
    "        \n",
    "        if len(anw) == 0:\n",
    "            continue\n",
    "        \n",
    "        RMSE_epoch_loss = 0\n",
    "        MSE_epoch_loss = 0\n",
    "        MAPE_epoch_loss = 0\n",
    "        count += anw.shape[0]\n",
    "\n",
    "        for index in anw:\n",
    "            index.to(DEVICE)\n",
    "            # LSTM\n",
    "            # output, _, _ = model(src)\n",
    "            \n",
    "            # GRU\n",
    "            # output, _ = model(src)\n",
    "            \n",
    "            # nlinear\n",
    "            # output, _ = model(src)\n",
    "            \n",
    "            # transformer\n",
    "            # src_mask = model.generate_square_subsequent_mask(src.shape[1]).to(src.device)\n",
    "            # output, _ = model(src, src_mask)\n",
    "            \n",
    "            # RMSE_loss = np.sqrt(mean_squared_error(output[index], trg[index]))\n",
    "            # MSE_loss = mean_squared_error(output[index], trg[index])\n",
    "            # MAPE_loss = MAPE(output[index], trg[index])\n",
    "            \n",
    "            # attention 계열\n",
    "            output = model(src, index, max_len)\n",
    "\n",
    "            RMSE_loss = np.sqrt(mean_squared_error(output, trg[index]))\n",
    "            MSE_loss = mean_squared_error(output, trg[index])\n",
    "            MAPE_loss = MAPE(output, trg[index])\n",
    "            \n",
    "        RMSE_total_loss += RMSE_loss\n",
    "        MSE_total_loss += MSE_loss\n",
    "        MAPE_total_loss += MAPE_loss\n",
    "\n",
    "    print(f'Test RMSE Loss: {RMSE_total_loss/count:.4f}')\n",
    "    print(f'Test MSE Loss: {MSE_total_loss/count:.4f}')\n",
    "    print(f'Test MAPE Loss: {MAPE_total_loss/count:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_12_dim\n",
    "dataset = Apartment_Complex_Dataset('None', table_1, table_2, table_3, 'None', ml_window_size, 'ML', 'TEST', DEVICE)\n",
    "dataloader = DataLoader(dataset, batch_size=ml_batch, shuffle=False, drop_last=True)\n",
    "\n",
    "# emb_1024_dim\n",
    "# model = torch.load('../데이터/Checkpoint/embedding_tr_0.8_lr_1e-05_wd_0_batch_128_epochs_131_e1_128_e2_128_e3_512_emb_1024_d1_512_d2_256_d3_128.pth', map_location=torch.device('cpu'))\n",
    "# dataset = Apartment_Complex_Dataset(model, table_1, table_2, table_3, embedding_dim, ml_window_size, 'ML', 'TEST', DEVICE)\n",
    "# dataloader = DataLoader(dataset, batch_size=ml_batch, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_criterion = np.sqrt(mean_squared_error())\n",
    "MSE_criterion = mean_squared_error()\n",
    "MAPE_criterion = MAPE()\n",
    "\n",
    "RMSE_total_loss = 0\n",
    "MSE_total_loss = 0\n",
    "MAE_total_loss = 0\n",
    "MAPE_total_loss = 0\n",
    "\n",
    "for i, data in enumerate(dataloader):\n",
    "    X, y = data[0].squeeze().cpu().numpy(), data[1].squeeze().cpu().numpy()\n",
    "    y_pred = model.predict(X)\n",
    "    RMSE_loss = RMSE_criterion(y, y_pred)\n",
    "    RMSE_total_loss += RMSE_loss/len(dataloader)\n",
    "    MSE_loss = MSE_criterion(y, y_pred)\n",
    "    MSE_total_loss += MSE_loss/len(dataloader)\n",
    "    MAPE_loss = MAPE_criterion(y, y_pred)\n",
    "    MAPE_total_loss += MAPE_loss/len(dataloader)\n",
    "\n",
    "print(f'Test RMSE Loss: {RMSE_total_loss:.4f}')\n",
    "print(f'Test MSE Loss: {MSE_total_loss:.4f}')\n",
    "print(f'Test MAE Loss: {MAE_total_loss:.4f}')\n",
    "print(f'Test MAPE Loss: {MAPE_total_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
