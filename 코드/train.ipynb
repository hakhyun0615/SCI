{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "from Dataset.Embedding_Dataset import Embedding_Dataset\n",
    "from Model.Embedding import Embedding\n",
    "\n",
    "from Dataset.LSTM_Dataset import LSTM_Dataset\n",
    "from Model.LSTM import LSTM\n",
    "\n",
    "from Dataset.Attention_Dataset import Attention_Dataset\n",
    "from Model.Attention import LSTMSeq2Seq\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device('cpu') # CPU\n",
    "# DEVICE = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu') # 맥\n",
    "# DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') # 윈도우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_lr = 0.0001\n",
    "embedding_batch = 512\n",
    "embedding_epochs = 150\n",
    "encoder_dim_1 = 256\n",
    "encoder_dim_2 = 512\n",
    "embedding_dim = 1024\n",
    "decoder_dim_1 = 512\n",
    "decoder_dim_2 = 256\n",
    "\n",
    "lstm_lr = 0.01\n",
    "lstm_batch = 1\n",
    "lstm_epochs = 50\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "window_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "connection_info = \"host=localhost dbname=postgres user=postgres password=hd219833 port=5432\"\n",
    "conn = psycopg2.connect(connection_info)\n",
    "table_1_query = '''\n",
    "    SELECT * FROM building\n",
    "    '''\n",
    "table_2_query = '''\n",
    "    SELECT * FROM economy\n",
    "    '''\n",
    "table_3_query = '''\n",
    "    SELECT * FROM building_price\n",
    "    '''\n",
    "table_1 = pd.read_sql(table_1_query,conn) \n",
    "table_2 = pd.read_sql(table_2_query,conn)\n",
    "table_3 = pd.read_sql(table_3_query,conn) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "\n",
    "dataset = Embedding_Dataset(table_1, table_2, table_3)\n",
    "dataset_length = len(dataset)\n",
    "split_point = int(train_ratio * len(dataset))\n",
    "train_indices = range(0, split_point)\n",
    "val_indices = range(split_point, dataset_length)\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=embedding_batch, shuffle=False, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=embedding_batch, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Train Loss: 1730666251.7802, Val Loss: 2000343256.0000\n",
      "Epoch [2/150], Train Loss: 1389706469.5385, Val Loss: 1948759809.8182\n",
      "Epoch [3/150], Train Loss: 1353726583.2088, Val Loss: 1911586928.3636\n",
      "Epoch [4/150], Train Loss: 1338561161.8462, Val Loss: 1858461872.3636\n",
      "Epoch [5/150], Train Loss: 1318496543.0330, Val Loss: 1810846856.7273\n",
      "Epoch [6/150], Train Loss: 1302268924.8352, Val Loss: 1783128981.4545\n",
      "Epoch [7/150], Train Loss: 1292255807.6484, Val Loss: 1758420232.7273\n",
      "Epoch [8/150], Train Loss: 1285839071.3846, Val Loss: 1762876040.3636\n",
      "Epoch [9/150], Train Loss: 1284901373.6264, Val Loss: 1722190139.2727\n",
      "Epoch [10/150], Train Loss: 1274100015.5604, Val Loss: 1687937882.1818\n",
      "Epoch [11/150], Train Loss: 1284591992.1758, Val Loss: 1657332623.2727\n",
      "Epoch [12/150], Train Loss: 1272329216.7912, Val Loss: 1626430347.2727\n",
      "Epoch [13/150], Train Loss: 1271899038.4176, Val Loss: 1643077994.5455\n",
      "Epoch [14/150], Train Loss: 1265622823.2967, Val Loss: 1595871924.3636\n",
      "Epoch [15/150], Train Loss: 1255233968.2637, Val Loss: 1570149257.4545\n",
      "Epoch [16/150], Train Loss: 1260740082.1978, Val Loss: 1538945637.0909\n",
      "Epoch [17/150], Train Loss: 1253692180.0440, Val Loss: 1547262577.0909\n",
      "Epoch [18/150], Train Loss: 1243826722.9890, Val Loss: 1511892651.6364\n",
      "Epoch [19/150], Train Loss: 1239277566.8571, Val Loss: 1509580434.1818\n",
      "Epoch [20/150], Train Loss: 1230449776.3516, Val Loss: 1463254621.0909\n",
      "Epoch [21/150], Train Loss: 1239875170.7253, Val Loss: 1478407322.1818\n",
      "Epoch [22/150], Train Loss: 1231791253.7143, Val Loss: 1455209874.9091\n",
      "Epoch [23/150], Train Loss: 1225340206.2418, Val Loss: 1438843686.5455\n",
      "Epoch [24/150], Train Loss: 1230351915.3407, Val Loss: 1432317597.8182\n",
      "Epoch [25/150], Train Loss: 1212396067.4286, Val Loss: 1390119288.7273\n",
      "Epoch [26/150], Train Loss: 1210300390.0659, Val Loss: 1395818187.6364\n",
      "Epoch [27/150], Train Loss: 1215828662.1538, Val Loss: 1368524688.0000\n",
      "Epoch [28/150], Train Loss: 1225117149.8901, Val Loss: 1410288750.5455\n",
      "Epoch [29/150], Train Loss: 1208583011.6044, Val Loss: 1356133640.0000\n",
      "Epoch [30/150], Train Loss: 1210946388.1319, Val Loss: 1380174635.6364\n",
      "Epoch [31/150], Train Loss: 1200311936.2637, Val Loss: 1343222232.7273\n",
      "Epoch [32/150], Train Loss: 1199269711.3846, Val Loss: 1341683815.2727\n",
      "Epoch [33/150], Train Loss: 1189777045.7143, Val Loss: 1331532315.6364\n",
      "Epoch [34/150], Train Loss: 1191929892.4835, Val Loss: 1314733332.3636\n",
      "Epoch [35/150], Train Loss: 1182092612.7473, Val Loss: 1291218672.7273\n",
      "Epoch [36/150], Train Loss: 1187481944.0879, Val Loss: 1308412270.5455\n",
      "Epoch [37/150], Train Loss: 1177676212.4835, Val Loss: 1285034437.0909\n",
      "Epoch [38/150], Train Loss: 1179470926.1538, Val Loss: 1296969924.3636\n",
      "Epoch [39/150], Train Loss: 1175610257.6703, Val Loss: 1279889249.4545\n",
      "Epoch [40/150], Train Loss: 1166899136.6154, Val Loss: 1236608937.4545\n",
      "Epoch [41/150], Train Loss: 1168726592.4396, Val Loss: 1274972123.6364\n",
      "Epoch [42/150], Train Loss: 1165599839.2088, Val Loss: 1246059114.1818\n",
      "Epoch [43/150], Train Loss: 1164113278.9451, Val Loss: 1265379449.4545\n",
      "Epoch [44/150], Train Loss: 1155460248.4396, Val Loss: 1228768819.6364\n",
      "Epoch [45/150], Train Loss: 1146043555.2527, Val Loss: 1213543992.7273\n",
      "Epoch [46/150], Train Loss: 1166862235.7802, Val Loss: 1254276002.9091\n",
      "Epoch [47/150], Train Loss: 1156220690.9011, Val Loss: 1242460765.8182\n",
      "Epoch [48/150], Train Loss: 1149993438.1538, Val Loss: 1196638475.6364\n",
      "Epoch [49/150], Train Loss: 1150718191.5604, Val Loss: 1207919885.0909\n",
      "Epoch [50/150], Train Loss: 1148891344.9670, Val Loss: 1195404827.6364\n",
      "Epoch [51/150], Train Loss: 1150483675.6044, Val Loss: 1220952058.9091\n",
      "Epoch [52/150], Train Loss: 1143857786.8132, Val Loss: 1181261205.0909\n",
      "Epoch [53/150], Train Loss: 1145773626.9011, Val Loss: 1195739312.0000\n",
      "Epoch [54/150], Train Loss: 1140413327.8242, Val Loss: 1197582303.2727\n",
      "Epoch [55/150], Train Loss: 1134877647.7363, Val Loss: 1200311679.2727\n",
      "Epoch [56/150], Train Loss: 1139200000.9670, Val Loss: 1167457912.0000\n",
      "Epoch [57/150], Train Loss: 1139626492.7473, Val Loss: 1188728464.7273\n",
      "Epoch [58/150], Train Loss: 1121824218.7253, Val Loss: 1144510278.5455\n",
      "Epoch [59/150], Train Loss: 1153519256.5275, Val Loss: 1199986528.0000\n",
      "Epoch [60/150], Train Loss: 1140352170.1099, Val Loss: 1160675341.0909\n",
      "Epoch [61/150], Train Loss: 1139096305.8462, Val Loss: 1170662915.6364\n",
      "Epoch [62/150], Train Loss: 1136789496.7033, Val Loss: 1159324042.9091\n",
      "Epoch [63/150], Train Loss: 1123124096.8791, Val Loss: 1156134700.3636\n",
      "Epoch [64/150], Train Loss: 1122385927.7363, Val Loss: 1149162666.9091\n",
      "Epoch [65/150], Train Loss: 1112984322.5495, Val Loss: 1125119227.6364\n",
      "Epoch [66/150], Train Loss: 1127146556.7473, Val Loss: 1143936368.7273\n",
      "Epoch [67/150], Train Loss: 1117111857.1429, Val Loss: 1134069304.0000\n",
      "Epoch [68/150], Train Loss: 1117516013.4505, Val Loss: 1141143586.9091\n",
      "Epoch [69/150], Train Loss: 1123238968.7033, Val Loss: 1150007424.7273\n",
      "Epoch [70/150], Train Loss: 1121316063.8242, Val Loss: 1143590384.7273\n",
      "Epoch [71/150], Train Loss: 1129511607.4725, Val Loss: 1168240486.5455\n",
      "Epoch [72/150], Train Loss: 1109087550.5934, Val Loss: 1102168490.9091\n",
      "Epoch [73/150], Train Loss: 1122227388.8352, Val Loss: 1141901201.4545\n",
      "Epoch [74/150], Train Loss: 1095537429.1868, Val Loss: 1100562238.5455\n",
      "Epoch [75/150], Train Loss: 1113509496.1758, Val Loss: 1126338698.9091\n",
      "Epoch [76/150], Train Loss: 1097835905.5824, Val Loss: 1085868930.9091\n",
      "Epoch [77/150], Train Loss: 1104542266.1099, Val Loss: 1122166522.1818\n",
      "Epoch [78/150], Train Loss: 1099125920.2637, Val Loss: 1088522973.8182\n",
      "Epoch [79/150], Train Loss: 1095376964.3956, Val Loss: 1107144921.4545\n",
      "Epoch [80/150], Train Loss: 1110476402.0220, Val Loss: 1119930187.6364\n",
      "Epoch [81/150], Train Loss: 1106705956.9231, Val Loss: 1110463275.6364\n",
      "Epoch [82/150], Train Loss: 1100807536.0000, Val Loss: 1095437410.9091\n",
      "Epoch [83/150], Train Loss: 1094611375.2088, Val Loss: 1101305305.4545\n",
      "Epoch [84/150], Train Loss: 1093420059.0769, Val Loss: 1082518818.1818\n",
      "Epoch [85/150], Train Loss: 1092313845.1868, Val Loss: 1093925971.6364\n",
      "Epoch [86/150], Train Loss: 1092425204.3077, Val Loss: 1079308806.5455\n",
      "Epoch [87/150], Train Loss: 1094953569.9341, Val Loss: 1092804842.9091\n",
      "Epoch [88/150], Train Loss: 1085683928.3516, Val Loss: 1070174165.8182\n",
      "Epoch [89/150], Train Loss: 1093234357.0989, Val Loss: 1081717645.0909\n",
      "Epoch [90/150], Train Loss: 1071440643.0769, Val Loss: 1063108855.2727\n",
      "Epoch [91/150], Train Loss: 1081465254.2418, Val Loss: 1068967653.8182\n",
      "Epoch [92/150], Train Loss: 1095001546.0220, Val Loss: 1098915869.8182\n",
      "Epoch [93/150], Train Loss: 1090399489.9341, Val Loss: 1067246784.7273\n",
      "Epoch [94/150], Train Loss: 1091754997.3626, Val Loss: 1090234161.4545\n",
      "Epoch [95/150], Train Loss: 1084397037.9780, Val Loss: 1072967791.2727\n",
      "Epoch [96/150], Train Loss: 1085838334.4176, Val Loss: 1060244977.4545\n",
      "Epoch [97/150], Train Loss: 1089110308.0440, Val Loss: 1074048232.7273\n",
      "Epoch [98/150], Train Loss: 1084389575.0330, Val Loss: 1053818005.8182\n",
      "Epoch [99/150], Train Loss: 1085147100.2198, Val Loss: 1074859416.0000\n",
      "Epoch [100/150], Train Loss: 1087927944.2637, Val Loss: 1067866632.0000\n",
      "Epoch [101/150], Train Loss: 1084321927.6484, Val Loss: 1054291347.6364\n",
      "Epoch [102/150], Train Loss: 1081020782.5495, Val Loss: 1056371156.3636\n",
      "Epoch [103/150], Train Loss: 1078764887.0330, Val Loss: 1067555821.8182\n",
      "Epoch [104/150], Train Loss: 1078298534.7253, Val Loss: 1052730936.0000\n",
      "Epoch [105/150], Train Loss: 1073346453.3626, Val Loss: 1052248775.2727\n",
      "Epoch [106/150], Train Loss: 1074093498.1978, Val Loss: 1052034269.8182\n",
      "Epoch [107/150], Train Loss: 1078272255.3846, Val Loss: 1049832469.8182\n",
      "Epoch [108/150], Train Loss: 1075702740.5714, Val Loss: 1048696248.7273\n",
      "Epoch [109/150], Train Loss: 1066522374.5934, Val Loss: 1040020968.7273\n",
      "Epoch [110/150], Train Loss: 1069754756.7912, Val Loss: 1035071490.1818\n",
      "Epoch [111/150], Train Loss: 1067443643.0769, Val Loss: 1030272301.0909\n",
      "Epoch [112/150], Train Loss: 1071404035.6923, Val Loss: 1052377579.6364\n",
      "Epoch [113/150], Train Loss: 1061554662.5934, Val Loss: 1040841080.7273\n",
      "Epoch [114/150], Train Loss: 1063083190.9451, Val Loss: 1040860382.5455\n",
      "Epoch [115/150], Train Loss: 1069770263.5604, Val Loss: 1035374502.5455\n",
      "Epoch [116/150], Train Loss: 1071190362.7253, Val Loss: 1035374502.5455\n",
      "Early Stop Triggered!\n"
     ]
    }
   ],
   "source": [
    "model = Embedding(encoder_dim_1, encoder_dim_2, embedding_dim, decoder_dim_1, decoder_dim_2).to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=embedding_lr)\n",
    "\n",
    "model.train()\n",
    "consecutive_train_loss_increases = 0\n",
    "max_consecutive_train_loss_increases = 3\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(embedding_epochs):\n",
    "    total_train_loss = 0\n",
    "    for data in train_dataloader:\n",
    "        input = data[0].to(DEVICE)\n",
    "        target = data[1].to(DEVICE)\n",
    "        output = model(input).to(DEVICE)\n",
    "\n",
    "        train_loss = criterion(output, target)\n",
    "        total_train_loss += train_loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    if len(train_losses) > 1 and train_losses[-1] > train_losses[-2]:\n",
    "        consecutive_train_loss_increases += 1\n",
    "        if consecutive_train_loss_increases >= max_consecutive_train_loss_increases:\n",
    "            print(f\"Early Stop Triggered!\")\n",
    "            torch.save(model, f'../데이터/Checkpoint/embedding_train_{train_ratio}_lr_{embedding_lr}_batch_{embedding_batch}_epochs_{embedding_epochs}_e1_{encoder_dim_1}_e2_{encoder_dim_1}_emb_{embedding_dim}_d1{decoder_dim_1}_d2{decoder_dim_2}.pth')\n",
    "            break\n",
    "    else:\n",
    "        consecutive_train_loss_increases = 0\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            input = data[0].to(DEVICE)\n",
    "            target = data[1].to(DEVICE)\n",
    "            output = model(input).to(DEVICE)\n",
    "\n",
    "            val_loss = criterion(output, target)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{embedding_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Validation Loss: 1030272301.0909091\n"
     ]
    }
   ],
   "source": [
    "def plot_train_val_losses(train_losses, val_losses):\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_train_val_losses(train_losses, val_losses)\n",
    "print(f'Min Validation Loss: {min(val_losses)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../데이터/Checkpoint/embedding_train_0.8_lr_0.01_batch_32_epochs_50_dim_6.pth')\n",
    "dataset = LSTM_Dataset(model, table_1, table_2, table_3, embedding_dim, window_size)\n",
    "\n",
    "train_ratio = 0.8\n",
    "dataset_length = len(dataset)\n",
    "split_point = int(train_ratio * len(dataset))\n",
    "train_indices = range(0, split_point)\n",
    "val_indices = range(split_point, dataset_length)\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=embedding_batch, shuffle=False, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=embedding_batch, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 4457084913.2495\n",
      "Epoch [2/50], Train Loss: 2639799669.2864\n",
      "Epoch [3/50], Train Loss: 1889211181.3742\n",
      "Epoch [4/50], Train Loss: 1621113765.7466\n",
      "Epoch [5/50], Train Loss: 1536347630.7305\n",
      "Epoch [6/50], Train Loss: 1508256809.3546\n",
      "Epoch [7/50], Train Loss: 1501316050.4178\n",
      "Epoch [8/50], Train Loss: 1496720547.7443\n",
      "Epoch [9/50], Train Loss: 1493436904.9662\n",
      "Epoch [10/50], Train Loss: 1491849440.4544\n",
      "Epoch [11/50], Train Loss: 1490709939.9167\n",
      "Epoch [12/50], Train Loss: 1490298252.6531\n",
      "Epoch [13/50], Train Loss: 1490066771.7568\n",
      "Epoch [14/50], Train Loss: 1489904553.6412\n",
      "Epoch [15/50], Train Loss: 1489809264.2112\n",
      "Epoch [16/50], Train Loss: 1489719638.4178\n",
      "Epoch [17/50], Train Loss: 1489666388.2125\n",
      "Epoch [18/50], Train Loss: 1489614520.1380\n",
      "Epoch [19/50], Train Loss: 1489531656.4119\n",
      "Epoch [20/50], Train Loss: 1489476864.0525\n",
      "Epoch [21/50], Train Loss: 1489432332.4914\n",
      "Epoch [22/50], Train Loss: 1489389663.6376\n",
      "Epoch [23/50], Train Loss: 1489300576.0239\n",
      "Epoch [24/50], Train Loss: 1489243003.7281\n",
      "Epoch [25/50], Train Loss: 1489210289.8569\n",
      "Epoch [26/50], Train Loss: 1489147177.3672\n",
      "Epoch [27/50], Train Loss: 1489087240.8590\n",
      "Epoch [28/50], Train Loss: 1489049705.3208\n",
      "Epoch [29/50], Train Loss: 1488954457.3110\n",
      "Epoch [30/50], Train Loss: 1488918861.9109\n",
      "Epoch [31/50], Train Loss: 1488849718.9130\n",
      "Epoch [32/50], Train Loss: 1488789314.3850\n",
      "Epoch [33/50], Train Loss: 1488730489.2280\n",
      "Epoch [34/50], Train Loss: 1488664809.6480\n",
      "Epoch [35/50], Train Loss: 1488615758.3526\n",
      "Epoch [36/50], Train Loss: 1488567962.9942\n",
      "Epoch [37/50], Train Loss: 1488495349.4339\n",
      "Epoch [38/50], Train Loss: 1488466819.5393\n",
      "Epoch [39/50], Train Loss: 1488416725.0039\n",
      "Epoch [40/50], Train Loss: 1488351656.2833\n",
      "Epoch [41/50], Train Loss: 1488283501.6679\n",
      "Epoch [42/50], Train Loss: 1488228943.3389\n",
      "Epoch [43/50], Train Loss: 1488196455.7372\n",
      "Epoch [44/50], Train Loss: 1488117979.1185\n",
      "Epoch [45/50], Train Loss: 1488069540.7553\n",
      "Epoch [46/50], Train Loss: 1488010932.9404\n",
      "Epoch [47/50], Train Loss: 1487973938.8470\n",
      "Epoch [48/50], Train Loss: 1487893113.0089\n",
      "Epoch [49/50], Train Loss: 1487875749.7484\n",
      "Epoch [50/50], Train Loss: 1487800924.4878\n"
     ]
    }
   ],
   "source": [
    "model = LSTM(embedding_dim, hidden_dim, output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lstm_lr)\n",
    "\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(lstm_epochs):\n",
    "    total_train_loss = 0\n",
    "    for data in train_dataloader:\n",
    "        src = data[0]\n",
    "        trg = data[1]\n",
    "\n",
    "        if trg.sum() != 0: \n",
    "            output = model(src)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            src = data[0]\n",
    "            trg = data[1]\n",
    "\n",
    "            if trg.sum() != 0:\n",
    "                output = model(src)\n",
    "\n",
    "                val_loss = criterion(output, trg)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{lstm_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "torch.save(model, f'../데이터/Checkpoint/lstm_lr_{lstm_lr}_batch_{lstm_batch}_epochs_{lstm_epochs}_hdim_{hidden_dim}_odim_{output_dim}_ws_{window_size}.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../데이터/Checkpoint/embedding_train_0.8_lr_0.01_batch_32_epochs_50_dim_6.pth')\n",
    "dataset = Attention_Dataset(model, table_1, table_2, table_3, embedding_dim, window_size)\n",
    "\n",
    "train_ratio = 0.8\n",
    "dataset_length = len(dataset)\n",
    "split_point = int(train_ratio * len(dataset))\n",
    "train_indices = range(0, split_point)\n",
    "val_indices = range(split_point, dataset_length)\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=embedding_batch, shuffle=False, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=embedding_batch, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('C:/Users/hkyoo/OneDrive/바탕 화면/SCI/데이터/Checkpoint/embedding_lr_0.01_batch_32_epochs_50_dim_6.pth')\n",
    "dataset = Attention_Dataset(model, table_1, table_2, table_3, embedding_dim, window_size)\n",
    "dataloader = DataLoader(dataset, batch_size=lstm_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0254], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 38\n",
    "window_size = 5\n",
    "mx_len = 1\n",
    "input = torch.randn(num, window_size, embedding_dim)\n",
    "\n",
    "model = LSTMSeq2Seq(embedding_dim, hidden_dim, output_dim, DEVICE)\n",
    "model(input,1, mx_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# 학습\n",
    "history = {'train_loss':[], 'val_loss':[], 'lr':[]}\n",
    "\n",
    "for epoch in range(att_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    num = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        src = batch[0][0].to(DEVICE)\n",
    "        max_len = batch[1][0].to(DEVICE)\n",
    "        anw = batch[2][0]\n",
    "        trg = batch[3][0].to(DEVICE)\n",
    "        \n",
    "        if len(anw)==0:\n",
    "            continue\n",
    "        \n",
    "        num += len(anw)\n",
    "        \n",
    "        dong_loss = 0\n",
    "        for index in anw:\n",
    "            index.to(DEVICE)\n",
    "            output = model(src, index, max_len)\n",
    "            loss = criterion(output, trg)\n",
    "            # dong_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # optimizer.zero_grad()\n",
    "        # # dong_loss /= len(anw)\n",
    "        # dong_loss = torch.tensor(dong_loss, requires_grad=True).to(DEVICE)\n",
    "        # dong_loss.backward()\n",
    "        # optimizer.step()\n",
    "    train_loss = epoch_loss / num\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    \n",
    "    \n",
    "\n",
    "#     if epoch%valid_every==0:\n",
    "#         print(\"==========================\")\n",
    "#         model.eval()\n",
    "#         epoch_loss = 0\n",
    "#         valid_num = 1e-9\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for i, batch in enumerate(val_loader):\n",
    "#                 src = batch[0].to(DEVICE)\n",
    "#                 trg = batch[1].to(DEVICE)\n",
    "#                 if(trg != 0):\n",
    "#                     output = model(src, trg)\n",
    "#                     loss = criterion(output, trg)\n",
    "#                     epoch_loss += loss.item()\n",
    "#                     valid_num += 1\n",
    "#         valid_loss = epoch_loss / valid_num\n",
    "            \n",
    "#         if valid_loss < best_valid_loss:\n",
    "#             best_valid_loss = valid_loss\n",
    "#             model.decoder.t=0\n",
    "#             torch.save(model.state_dict(), 'lstm-model.pt')\n",
    "#         print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
    "\n",
    "#         history['train_loss'].append(train_loss)\n",
    "#         history['val_loss'].append(valid_loss)\n",
    "#         history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "# plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('C:/Users/hkyoo/OneDrive/바탕 화면/SCI/데이터/Checkpoint/embedding_lr_0.01_batch_32_epochs_50_dim_6.pth')\n",
    "\n",
    "dataset = LSTM_Dataset(model, table_1, table_2, table_3, embedding_dim, window_size)\n",
    "dataloader = DataLoader(dataset, batch_size=lstm_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_dim, out_dim, nhead, nlayers\n",
    "model = TFModel(embedding_dim, window_size, output_dim, 2, 2)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lstm_lr)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(lstm_epochs):\n",
    "    epoch_loss = 0\n",
    "    train_num = 1e-9\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        src = batch[0].to(DEVICE)\n",
    "        trg = batch[1].to(DEVICE)\n",
    "        if(trg != 0):\n",
    "            train_num += 1\n",
    "            optimizer.zero_grad()\n",
    "            src_mask = model.generate_square_subsequent_mask(src.shape[1]).to(src.device)\n",
    "            output = model(src, src_mask)\n",
    "            loss = criterion(output[0], trg)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "    train_loss = epoch_loss / train_num\n",
    "    print(f'Epoch [{epoch+1}/{embedding_epochs}], Train Loss: {train_loss:.4f}')\n",
    "\n",
    "torch.save(model, f'../데이터/Checkpoint/lstm_lsr_{lstm_lr}_batch_{lstm_batch}_epochs_{lstm_epochs}_hdim_{hidden_dim}_odim_{output_dim}_ws{window_size}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('C:/Users/hkyoo/OneDrive/바탕 화면/SCI/데이터/Checkpoint/embedding_lr_0.01_batch_32_epochs_50_dim_6.pth')\n",
    "\n",
    "dataset = LSTM_Dataset(model, table_1, table_2, table_3, embedding_dim, window_size)\n",
    "dataloader = DataLoader(dataset, batch_size=lstm_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLinear(embedding_dim, window_size, output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lstm_lr)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(lstm_epochs):\n",
    "    epoch_loss = 0\n",
    "    train_num = 1e-9\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        src = batch[0].to(DEVICE)\n",
    "        trg = batch[1].to(DEVICE)\n",
    "        if(trg != 0):\n",
    "            train_num += 1\n",
    "            optimizer.zero_grad()\n",
    "            output = model(src)\n",
    "            loss = criterion(output[0], trg)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "    train_loss = epoch_loss / train_num\n",
    "    print(f'Epoch [{epoch+1}/{embedding_epochs}], Train Loss: {train_loss:.4f}')\n",
    "\n",
    "torch.save(model, f'../데이터/Checkpoint/lstm_lsr_{lstm_lr}_batch_{lstm_batch}_epochs_{lstm_epochs}_hdim_{hidden_dim}_odim_{output_dim}_ws{window_size}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
