{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "from Dataset.Embedding_Dataset import Embedding_Dataset\n",
    "from Model.Embedding import Embedding\n",
    "\n",
    "from Dataset.LSTM_Dataset import LSTM_Dataset\n",
    "from Model.LSTM import LSTM\n",
    "from Model.NLinear import NLinear\n",
    "from Model.Transformer import Transformer\n",
    "\n",
    "from Dataset.Attention_Dataset import Attention_Dataset\n",
    "from Model.Attention import LSTMSeq2Seq\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# DEVICE = torch.device('cpu') # CPU\n",
    "# DEVICE = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu') # MAC\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # WINDOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection_info = \"host=localhost dbname=postgres user=postgres password=hd219833 port=5432\"\n",
    "# conn = psycopg2.connect(connection_info)\n",
    "# table_1_query = '''\n",
    "#     SELECT * FROM building\n",
    "#     '''\n",
    "# table_2_query = '''\n",
    "#     SELECT * FROM economy\n",
    "#     '''\n",
    "# table_3_query = '''\n",
    "#     SELECT * FROM building_price\n",
    "#     '''\n",
    "# table_1 = pd.read_sql(table_1_query,conn) \n",
    "# table_2 = pd.read_sql(table_2_query,conn)\n",
    "# table_3 = pd.read_sql(table_3_query,conn) \n",
    "\n",
    "table_1 = pd.read_csv('../데이터/Table/table_1.csv') \n",
    "table_2 = pd.read_csv('../데이터/Table/table_2.csv') \n",
    "table_3 = pd.read_csv('../데이터/Table/table_3.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSE,self).__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = 1e-7\n",
    "\n",
    "    def forward(self, y, y_hat):\n",
    "        return torch.sqrt(self.mse(y, y_hat) + self.eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_losses(train_losses, val_losses):\n",
    "    print(f'Min Validation Loss: {min(val_losses)}')\n",
    "    plt.plot(train_losses[1:], label='Training Loss')\n",
    "    plt.plot(val_losses[1:], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val loss가 연속적으로 오를 때\n",
    "def early_stop_1(val_losses, consecutive_val_loss_increases, max_consecutive_val_loss_increases):\n",
    "    if len(val_losses) > 1 and val_losses[-1] > val_losses[-2]:\n",
    "        consecutive_val_loss_increases += 1\n",
    "        if consecutive_val_loss_increases >= max_consecutive_val_loss_increases:\n",
    "            return True, consecutive_val_loss_increases\n",
    "        else:\n",
    "            return False, consecutive_val_loss_increases\n",
    "    else:\n",
    "        consecutive_val_loss_increases = 0\n",
    "        return False, consecutive_val_loss_increases\n",
    "\n",
    "# val loss가 최저 loss보다 연속적으로 클 때\n",
    "def early_stop_2(avg_val_loss, best_val_loss, consecutive_val_loss_increases, max_consecutive_val_loss_increases):\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        consecutive_val_loss_increases = 0\n",
    "    else:\n",
    "        consecutive_val_loss_increases += 1\n",
    "    if consecutive_val_loss_increases >= max_consecutive_val_loss_increases:\n",
    "        return True, best_val_loss, consecutive_val_loss_increases\n",
    "    else:\n",
    "        return False, best_val_loss, consecutive_val_loss_increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "\n",
    "embedding_lr = 0.00001\n",
    "embedding_weight_decay = 0\n",
    "embedding_batch = 128\n",
    "embedding_epochs = 150\n",
    "encoder_dim_1 = 128\n",
    "encoder_dim_2 = 256\n",
    "encoder_dim_3 = 512\n",
    "embedding_dim = 1024\n",
    "decoder_dim_1 = 512\n",
    "decoder_dim_2 = 256\n",
    "decoder_dim_3 = 128\n",
    "\n",
    "lstm_lr = 0.0001\n",
    "lstm_weight_decay = 0\n",
    "lstm_batch = 128\n",
    "lstm_epochs = 150\n",
    "lstm_hidden_dim = 256\n",
    "lstm_window_size = 10\n",
    "\n",
    "nlinear_lr = 0.0001\n",
    "nlinear_weight_decay = 0\n",
    "nlinear_batch = 128\n",
    "nlinear_epochs = 150\n",
    "nlinear_window_size = 10\n",
    "\n",
    "attention_lr = 0.0001\n",
    "attention_weight_decay = 0\n",
    "attention_batch = 1\n",
    "attention_epochs = 150\n",
    "attention_hidden_dim = 256\n",
    "attention_window_size = 10\n",
    "\n",
    "transformer_lr = 0.0001\n",
    "transformer_weight_decay = 0\n",
    "transformer_batch = 1\n",
    "transformer_epochs = 150\n",
    "transformer_window_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Embedding_Dataset(table_1, table_2, table_3)\n",
    "dataset_length = len(dataset)\n",
    "split_point = int(train_ratio * len(dataset))\n",
    "train_indices = range(0, split_point)\n",
    "val_indices = range(split_point, dataset_length)\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=embedding_batch, shuffle=False, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=embedding_batch, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Train Loss: 6.3301, Val Loss: 5.9672\n",
      "Epoch [2/150], Train Loss: 5.8953, Val Loss: 5.6417\n",
      "Epoch [3/150], Train Loss: 5.5364, Val Loss: 5.4437\n",
      "Epoch [4/150], Train Loss: 5.2410, Val Loss: 5.2992\n",
      "Epoch [5/150], Train Loss: 4.9869, Val Loss: 5.1627\n",
      "Epoch [6/150], Train Loss: 4.7539, Val Loss: 5.0473\n",
      "Epoch [7/150], Train Loss: 4.5318, Val Loss: 4.9524\n",
      "Epoch [8/150], Train Loss: 4.3158, Val Loss: 4.8586\n",
      "Epoch [9/150], Train Loss: 4.1043, Val Loss: 4.7725\n",
      "Epoch [10/150], Train Loss: 3.8965, Val Loss: 4.6668\n",
      "Epoch [11/150], Train Loss: 3.6904, Val Loss: 4.5651\n",
      "Epoch [12/150], Train Loss: 3.4889, Val Loss: 4.4741\n",
      "Epoch [13/150], Train Loss: 3.2935, Val Loss: 4.3737\n",
      "Epoch [14/150], Train Loss: 3.1106, Val Loss: 4.2631\n",
      "Epoch [15/150], Train Loss: 2.9453, Val Loss: 4.1554\n",
      "Epoch [16/150], Train Loss: 2.7997, Val Loss: 4.0588\n",
      "Epoch [17/150], Train Loss: 2.6745, Val Loss: 3.9656\n",
      "Epoch [18/150], Train Loss: 2.5675, Val Loss: 3.8940\n",
      "Epoch [19/150], Train Loss: 2.4761, Val Loss: 3.7912\n",
      "Epoch [20/150], Train Loss: 2.3977, Val Loss: 3.7294\n",
      "Epoch [21/150], Train Loss: 2.3321, Val Loss: 3.6499\n",
      "Epoch [22/150], Train Loss: 2.2795, Val Loss: 3.5833\n",
      "Epoch [23/150], Train Loss: 2.2462, Val Loss: 3.6490\n",
      "Epoch [24/150], Train Loss: 2.2188, Val Loss: 3.5133\n",
      "Epoch [25/150], Train Loss: 2.1938, Val Loss: 3.6962\n",
      "Epoch [26/150], Train Loss: 2.1623, Val Loss: 3.5237\n",
      "Epoch [27/150], Train Loss: 2.1395, Val Loss: 3.5649\n",
      "Epoch [28/150], Train Loss: 2.1135, Val Loss: 3.4010\n",
      "Epoch [29/150], Train Loss: 2.0940, Val Loss: 3.3844\n",
      "Epoch [30/150], Train Loss: 2.0735, Val Loss: 3.3259\n",
      "Epoch [31/150], Train Loss: 2.0569, Val Loss: 3.2717\n",
      "Epoch [32/150], Train Loss: 2.0387, Val Loss: 3.2748\n",
      "Epoch [33/150], Train Loss: 2.0227, Val Loss: 3.2322\n",
      "Epoch [34/150], Train Loss: 2.0053, Val Loss: 3.2736\n",
      "Epoch [35/150], Train Loss: 1.9894, Val Loss: 3.1772\n",
      "Epoch [36/150], Train Loss: 1.9745, Val Loss: 3.2924\n",
      "Epoch [37/150], Train Loss: 1.9607, Val Loss: 3.1885\n",
      "Epoch [38/150], Train Loss: 1.9462, Val Loss: 3.2713\n",
      "Epoch [39/150], Train Loss: 1.9316, Val Loss: 3.2331\n",
      "Epoch [40/150], Train Loss: 1.9179, Val Loss: 3.2443\n",
      "Epoch [41/150], Train Loss: 1.9023, Val Loss: 3.2273\n",
      "Epoch [42/150], Train Loss: 1.8902, Val Loss: 3.3011\n",
      "Epoch [43/150], Train Loss: 1.8742, Val Loss: 3.1435\n",
      "Epoch [44/150], Train Loss: 1.8616, Val Loss: 3.3147\n",
      "Epoch [45/150], Train Loss: 1.8462, Val Loss: 3.1510\n",
      "Epoch [46/150], Train Loss: 1.8337, Val Loss: 3.2469\n",
      "Epoch [47/150], Train Loss: 1.8178, Val Loss: 3.2101\n",
      "Epoch [48/150], Train Loss: 1.8050, Val Loss: 3.2662\n",
      "Epoch [49/150], Train Loss: 1.7936, Val Loss: 3.1741\n",
      "Epoch [50/150], Train Loss: 1.7785, Val Loss: 3.2759\n",
      "Epoch [51/150], Train Loss: 1.7662, Val Loss: 3.1468\n",
      "Epoch [52/150], Train Loss: 1.7525, Val Loss: 3.2358\n",
      "Epoch [53/150], Train Loss: 1.7374, Val Loss: 3.1433\n",
      "Epoch [54/150], Train Loss: 1.7240, Val Loss: 3.2890\n",
      "Epoch [55/150], Train Loss: 1.7092, Val Loss: 3.1493\n",
      "Epoch [56/150], Train Loss: 1.6986, Val Loss: 3.2514\n",
      "Epoch [57/150], Train Loss: 1.6841, Val Loss: 3.2156\n",
      "Epoch [58/150], Train Loss: 1.6699, Val Loss: 3.2281\n",
      "Epoch [59/150], Train Loss: 1.6542, Val Loss: 3.2672\n",
      "Epoch [60/150], Train Loss: 1.6405, Val Loss: 3.2064\n",
      "Epoch [61/150], Train Loss: 1.6294, Val Loss: 3.2870\n",
      "Epoch [62/150], Train Loss: 1.6156, Val Loss: 3.2173\n",
      "Epoch [63/150], Train Loss: 1.6046, Val Loss: 3.3044\n",
      "Epoch [64/150], Train Loss: 1.5896, Val Loss: 3.1647\n",
      "Epoch [65/150], Train Loss: 1.5790, Val Loss: 3.2513\n",
      "Epoch [66/150], Train Loss: 1.5661, Val Loss: 3.1458\n",
      "Epoch [67/150], Train Loss: 1.5531, Val Loss: 3.1919\n",
      "Epoch [68/150], Train Loss: 1.5397, Val Loss: 3.1427\n",
      "Epoch [69/150], Train Loss: 1.5266, Val Loss: 3.1679\n",
      "Epoch [70/150], Train Loss: 1.5115, Val Loss: 3.1675\n",
      "Epoch [71/150], Train Loss: 1.4974, Val Loss: 3.1365\n",
      "Epoch [72/150], Train Loss: 1.4824, Val Loss: 3.1371\n",
      "Epoch [73/150], Train Loss: 1.4726, Val Loss: 3.1281\n",
      "Epoch [74/150], Train Loss: 1.4621, Val Loss: 3.1327\n",
      "Epoch [75/150], Train Loss: 1.4501, Val Loss: 3.1368\n",
      "Epoch [76/150], Train Loss: 1.4360, Val Loss: 3.1284\n",
      "Epoch [77/150], Train Loss: 1.4246, Val Loss: 3.1120\n",
      "Epoch [78/150], Train Loss: 1.4112, Val Loss: 3.1328\n",
      "Epoch [79/150], Train Loss: 1.3989, Val Loss: 3.0994\n",
      "Epoch [80/150], Train Loss: 1.3860, Val Loss: 3.0912\n",
      "Epoch [81/150], Train Loss: 1.3732, Val Loss: 3.1313\n",
      "Epoch [82/150], Train Loss: 1.3627, Val Loss: 3.0868\n",
      "Epoch [83/150], Train Loss: 1.3521, Val Loss: 3.1989\n",
      "Epoch [84/150], Train Loss: 1.3397, Val Loss: 3.0989\n",
      "Epoch [85/150], Train Loss: 1.3262, Val Loss: 3.1770\n",
      "Epoch [86/150], Train Loss: 1.3167, Val Loss: 3.1761\n",
      "Epoch [87/150], Train Loss: 1.3088, Val Loss: 3.1771\n",
      "Epoch [88/150], Train Loss: 1.2964, Val Loss: 3.1364\n",
      "Epoch [89/150], Train Loss: 1.2876, Val Loss: 3.0504\n",
      "Epoch [90/150], Train Loss: 1.2786, Val Loss: 3.0630\n",
      "Epoch [91/150], Train Loss: 1.2657, Val Loss: 3.0017\n",
      "Epoch [92/150], Train Loss: 1.2540, Val Loss: 3.0462\n",
      "Epoch [93/150], Train Loss: 1.2447, Val Loss: 3.0240\n",
      "Epoch [94/150], Train Loss: 1.2310, Val Loss: 3.0613\n",
      "Epoch [95/150], Train Loss: 1.2264, Val Loss: 3.1349\n",
      "Epoch [96/150], Train Loss: 1.2181, Val Loss: 3.0864\n",
      "Epoch [97/150], Train Loss: 1.2119, Val Loss: 3.0527\n",
      "Epoch [98/150], Train Loss: 1.2012, Val Loss: 3.0341\n",
      "Epoch [99/150], Train Loss: 1.1918, Val Loss: 2.9983\n",
      "Epoch [100/150], Train Loss: 1.1881, Val Loss: 3.0273\n",
      "Epoch [101/150], Train Loss: 1.1847, Val Loss: 2.9906\n",
      "Epoch [102/150], Train Loss: 1.1685, Val Loss: 3.1220\n",
      "Epoch [103/150], Train Loss: 1.1636, Val Loss: 3.1546\n",
      "Epoch [104/150], Train Loss: 1.1566, Val Loss: 2.9952\n",
      "Epoch [105/150], Train Loss: 1.1463, Val Loss: 3.0105\n",
      "Epoch [106/150], Train Loss: 1.1353, Val Loss: 2.9984\n",
      "Epoch [107/150], Train Loss: 1.1336, Val Loss: 3.0761\n",
      "Epoch [108/150], Train Loss: 1.1182, Val Loss: 3.0603\n",
      "Epoch [109/150], Train Loss: 1.1150, Val Loss: 3.1646\n",
      "Epoch [110/150], Train Loss: 1.1040, Val Loss: 3.0447\n",
      "Epoch [111/150], Train Loss: 1.1003, Val Loss: 3.1232\n",
      "Epoch [112/150], Train Loss: 1.0905, Val Loss: 3.0275\n",
      "Epoch [113/150], Train Loss: 1.0813, Val Loss: 3.1161\n",
      "Epoch [114/150], Train Loss: 1.0760, Val Loss: 3.0248\n",
      "Epoch [115/150], Train Loss: 1.0685, Val Loss: 3.0689\n",
      "Epoch [116/150], Train Loss: 1.0567, Val Loss: 3.0149\n",
      "Epoch [117/150], Train Loss: 1.0504, Val Loss: 3.0856\n",
      "Epoch [118/150], Train Loss: 1.0454, Val Loss: 3.0509\n",
      "Epoch [119/150], Train Loss: 1.0386, Val Loss: 3.1906\n",
      "Epoch [120/150], Train Loss: 1.0354, Val Loss: 2.9929\n",
      "Epoch [121/150], Train Loss: 1.0254, Val Loss: 3.1973\n",
      "Epoch [122/150], Train Loss: 1.0222, Val Loss: 3.0201\n",
      "Epoch [123/150], Train Loss: 1.0134, Val Loss: 3.0415\n",
      "Epoch [124/150], Train Loss: 1.0094, Val Loss: 3.0135\n",
      "Epoch [125/150], Train Loss: 1.0038, Val Loss: 3.0875\n",
      "Epoch [126/150], Train Loss: 0.9999, Val Loss: 3.0187\n",
      "Epoch [127/150], Train Loss: 0.9924, Val Loss: 3.0257\n",
      "Epoch [128/150], Train Loss: 0.9843, Val Loss: 2.9132\n",
      "Epoch [129/150], Train Loss: 0.9797, Val Loss: 2.9476\n",
      "Epoch [130/150], Train Loss: 0.9759, Val Loss: 2.9602\n",
      "Epoch [131/150], Train Loss: 0.9662, Val Loss: 3.0338 \n",
      "Early Stop Triggered!\n",
      "Min Validation Loss: 2.9132384743009294\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Embedding(encoder_dim_1, encoder_dim_2, encoder_dim_3, embedding_dim, decoder_dim_1, decoder_dim_2, decoder_dim_3).to(DEVICE)\n",
    "criterion = RMSE()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=embedding_lr, weight_decay=embedding_weight_decay)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "consecutive_val_loss_increases = 0\n",
    "max_consecutive_val_loss_increases = 3\n",
    "\n",
    "for epoch in range(embedding_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for data in train_dataloader:\n",
    "        input = data[0].to(DEVICE)\n",
    "        target = data[1].to(DEVICE)\n",
    "        output = model(input).to(DEVICE)\n",
    "\n",
    "        train_loss = criterion(output, target)\n",
    "        total_train_loss += train_loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            input = data[0].to(DEVICE)\n",
    "            target = data[1].to(DEVICE)\n",
    "            output = model(input).to(DEVICE)\n",
    "\n",
    "            val_loss = criterion(output, target)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    early_stop, consecutive_val_loss_increases = early_stop_1(val_losses, consecutive_val_loss_increases, max_consecutive_val_loss_increases)\n",
    "    # early_stop, best_val_loss, consecutive_val_loss_increases = early_stop_2(avg_val_loss, best_val_loss, consecutive_val_loss_increases, max_consecutive_val_loss_increases)\n",
    "    if early_stop:\n",
    "        print(f'Epoch [{epoch+1}/{embedding_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f} \\nEarly Stop Triggered!')\n",
    "        torch.save(model, f'../데이터/Checkpoint/embedding_tr_{train_ratio}_lr_{embedding_lr}_wd_{embedding_weight_decay}_batch_{embedding_batch}_epochs_{epoch+1}_e1_{encoder_dim_1}_e2_{encoder_dim_1}_e3_{encoder_dim_3}_emb_{embedding_dim}_d1{decoder_dim_1}_d2_{decoder_dim_2}_d3_{decoder_dim_3}.pth')\n",
    "        break\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{embedding_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "plot_train_val_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../데이터/Checkpoint/embedding_tr_0.8_lr_1e-05_wd_0_batch_128_epochs_131_e1_128_e2_128_e3_512_emb_1024_d1512_d2_256_d3_128.pth')\n",
    "dataset = LSTM_Dataset(model, table_1, table_2, table_3, embedding_dim, lstm_window_size, DEVICE)\n",
    "\n",
    "dataset_length = len(dataset)\n",
    "split_point = int(train_ratio * len(dataset))\n",
    "train_indices = range(0, split_point)\n",
    "val_indices = range(split_point, dataset_length)\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=embedding_batch, shuffle=False, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=embedding_batch, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Train Loss: 3.4132, Val Loss: 3.5306\n",
      "Epoch [2/150], Train Loss: 3.2753, Val Loss: 3.4851\n",
      "Epoch [3/150], Train Loss: 3.2069, Val Loss: 3.4720\n",
      "Epoch [4/150], Train Loss: 3.1649, Val Loss: 3.4758\n",
      "Epoch [5/150], Train Loss: 3.1296, Val Loss: 3.4654\n",
      "Epoch [6/150], Train Loss: 3.1009, Val Loss: 3.4549\n",
      "Epoch [7/150], Train Loss: 3.0723, Val Loss: 3.4430\n",
      "Epoch [8/150], Train Loss: 3.0526, Val Loss: 3.4415\n",
      "Epoch [9/150], Train Loss: 3.0310, Val Loss: 3.4395\n",
      "Epoch [10/150], Train Loss: 3.0113, Val Loss: 3.4461\n",
      "Epoch [11/150], Train Loss: 2.9967, Val Loss: 3.4032\n",
      "Epoch [12/150], Train Loss: 2.9821, Val Loss: 3.4734\n",
      "Epoch [13/150], Train Loss: 2.9724, Val Loss: 3.4351\n",
      "Epoch [14/150], Train Loss: 2.9668, Val Loss: 3.4177\n",
      "Epoch [15/150], Train Loss: 2.9556, Val Loss: 3.4411\n",
      "Epoch [16/150], Train Loss: 2.9467, Val Loss: 3.4693\n",
      "Epoch [17/150], Train Loss: 2.9383, Val Loss: 3.4249\n",
      "Epoch [18/150], Train Loss: 2.9398, Val Loss: 3.3901\n",
      "Epoch [19/150], Train Loss: 2.9298, Val Loss: 3.4544\n",
      "Epoch [20/150], Train Loss: 2.9160, Val Loss: 3.4741\n",
      "Epoch [21/150], Train Loss: 2.9083, Val Loss: 3.4062\n",
      "Epoch [22/150], Train Loss: 2.9035, Val Loss: 3.4211\n",
      "Epoch [23/150], Train Loss: 2.8979, Val Loss: 3.4892\n",
      "Epoch [24/150], Train Loss: 2.8956, Val Loss: 3.4092\n",
      "Epoch [25/150], Train Loss: 2.8960, Val Loss: 3.3967\n",
      "Epoch [26/150], Train Loss: 2.8931, Val Loss: 3.4276\n",
      "Epoch [27/150], Train Loss: 2.8859, Val Loss: 3.4329\n",
      "Epoch [28/150], Train Loss: 2.8826, Val Loss: 3.4232\n",
      "Epoch [29/150], Train Loss: 2.8779, Val Loss: 3.3914\n",
      "Epoch [30/150], Train Loss: 2.8727, Val Loss: 3.3824\n",
      "Epoch [31/150], Train Loss: 2.8706, Val Loss: 3.3656\n",
      "Epoch [32/150], Train Loss: 2.8691, Val Loss: 3.3769\n",
      "Epoch [33/150], Train Loss: 2.8617, Val Loss: 3.3409\n",
      "Epoch [34/150], Train Loss: 2.8591, Val Loss: 3.3569\n",
      "Epoch [35/150], Train Loss: 2.8551, Val Loss: 3.3696\n",
      "Epoch [36/150], Train Loss: 2.8540, Val Loss: 3.3727 \n",
      "Early Stop Triggered!\n",
      "Min Validation Loss: 3.340923787006792\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LSTM(embedding_dim, lstm_hidden_dim).to(DEVICE)\n",
    "criterion = RMSE()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lstm_lr, weight_decay=lstm_weight_decay)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "consecutive_val_loss_increases = 0\n",
    "max_consecutive_val_loss_increases = 3\n",
    "\n",
    "for epoch in range(lstm_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for data in train_dataloader:\n",
    "        src = data[0].to(DEVICE)\n",
    "        trg = data[1].to(DEVICE)\n",
    "\n",
    "        if trg.sum() != 0: \n",
    "            output, _, _ = model(src)\n",
    "            \n",
    "            train_loss = criterion(output, trg)\n",
    "            total_train_loss += train_loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            src = data[0].to(DEVICE)\n",
    "            trg = data[1].to(DEVICE)\n",
    "\n",
    "            if trg.sum() != 0:\n",
    "                output, _, _ = model(src)\n",
    "\n",
    "                val_loss = criterion(output, trg)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    early_stop, consecutive_val_loss_increases = early_stop_1(val_losses, consecutive_val_loss_increases, max_consecutive_val_loss_increases)\n",
    "    # early_stop, best_val_loss, consecutive_val_loss_increases = early_stop_2(avg_val_loss, best_val_loss, consecutive_val_loss_increases, max_consecutive_val_loss_increases)\n",
    "    if early_stop:\n",
    "        print(f'Epoch [{epoch+1}/{embedding_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f} \\nEarly Stop Triggered!')\n",
    "        torch.save(model, f'../데이터/Checkpoint/lstm_tr_{train_ratio}_lr_{lstm_lr}_wd_{lstm_weight_decay}_batch_{lstm_batch}_epochs_{epoch+1}_hdim_{lstm_hidden_dim}_ws_{lstm_window_size}.pth')\n",
    "        break\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{lstm_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "plot_train_val_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../데이터/Checkpoint/embedding_tr_0.8_lr_1e-05_wd_0_batch_128_epochs_131_e1_128_e2_128_e3_512_emb_1024_d1512_d2_256_d3_128.pth')\n",
    "dataset = LSTM_Dataset(model, table_1, table_2, table_3, embedding_dim, nlinear_window_size, DEVICE)\n",
    "\n",
    "dataset_length = len(dataset)\n",
    "split_point = int(train_ratio * len(dataset))\n",
    "train_indices = range(0, split_point)\n",
    "val_indices = range(split_point, dataset_length)\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=nlinear_batch, shuffle=False, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=nlinear_batch, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Train Loss: 0.3290, Val Loss: 0.2193\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     25\u001b[0m         train_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 26\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m total_train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n\u001b[0;32m     29\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(avg_train_loss)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:305\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[0;32m    303\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 305\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = NLinear(embedding_dim, nlinear_window_size).to(DEVICE)\n",
    "criterion = RMSE()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=nlinear_lr, weight_decay=nlinear_weight_decay)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "consecutive_val_loss_increases = 0\n",
    "max_consecutive_val_loss_increases = 3\n",
    "\n",
    "for epoch in range(nlinear_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for data in train_dataloader:\n",
    "        src = data[0].to(DEVICE)\n",
    "        trg = data[1].to(DEVICE)\n",
    "\n",
    "        if trg.sum() != 0:\n",
    "            output = model(src)\n",
    "\n",
    "            train_loss = criterion(output, trg)\n",
    "            total_train_loss += train_loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            src = data[0].to(DEVICE)\n",
    "            trg = data[1].to(DEVICE)\n",
    "\n",
    "            if trg.sum() != 0:\n",
    "                output = model(src)\n",
    "\n",
    "                val_loss = criterion(output, trg)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    early_stop, consecutive_val_loss_increases = early_stop_1(val_losses, consecutive_val_loss_increases, max_consecutive_val_loss_increases)\n",
    "    # early_stop, best_val_loss, consecutive_val_loss_increases = early_stop_2(avg_val_loss, best_val_loss, consecutive_val_loss_increases, max_consecutive_val_loss_increases)\n",
    "    if early_stop:\n",
    "        print(f'Epoch [{epoch+1}/{embedding_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f} \\nEarly Stop Triggered!')\n",
    "        torch.save(model, f'../데이터/Checkpoint/nlinear_tr_{train_ratio}_lr_{nlinear_lr}_wd_{nlinear_weight_decay}_batch_{nlinear_batch}_epochs_{epoch+1}_emb_{embedding_dim}_ws_{nlinear_window_size}.pth')\n",
    "        break\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{lstm_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "plot_train_val_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../데이터/Checkpoint/embedding_tr_0.8_lr_1e-05_wd_0_batch_128_epochs_131_e1_128_e2_128_e3_512_emb_1024_d1512_d2_256_d3_128.pth')\n",
    "dataset = Attention_Dataset(model, table_1, table_2, table_3, embedding_dim, attention_window_size)\n",
    "\n",
    "dataset_length = len(dataset)\n",
    "split_point = int(train_ratio * len(dataset))\n",
    "train_indices = range(0, split_point)\n",
    "val_indices = range(split_point, dataset_length)\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=attention_batch, shuffle=False, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=attention_batch, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Train Loss: 1.330557, Val Loss: 2.377012\n",
      "Epoch [2/150], Train Loss: 1.180837, Val Loss: 2.293077\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     13\u001b[0m total_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m     15\u001b[0m     src \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     16\u001b[0m     max_len \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:175\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:141\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    139\u001b[0m         storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    140\u001b[0m         out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr_\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring_\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndarray\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemmap\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;66;03m# array of string classes and object\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LSTMSeq2Seq(embedding_dim, attention_hidden_dim, 1).to(DEVICE)\n",
    "criterion = RMSE()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=attention_lr, weight_decay=attention_weight_decay)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "consecutive_val_loss_increases = 0\n",
    "max_consecutive_val_loss_increases = 3\n",
    "\n",
    "for epoch in range(attention_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for data in train_dataloader:\n",
    "        src = data[0][0].to(DEVICE)\n",
    "        max_len = data[1][0].to(DEVICE)\n",
    "        anw = data[2][0].to(DEVICE)\n",
    "        trg = data[3][0].to(DEVICE)\n",
    "        \n",
    "        if len(anw)==0:\n",
    "            continue\n",
    "    \n",
    "        # dong_loss = 0\n",
    "\n",
    "        for index in anw:\n",
    "            output = model(src, index, max_len)\n",
    "\n",
    "            train_loss = criterion(output, trg[index])\n",
    "            total_train_loss += train_loss.item()\n",
    "            # dong_loss += loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "        # # dong_loss /= len(anw)\n",
    "        # dong_loss = torch.tensor(dong_loss, requires_grad=True).to(DEVICE)\n",
    "        # dong_loss.backward()\n",
    "        # optimizer.step()\n",
    "            \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            src = data[0][0].to(DEVICE)\n",
    "            max_len = data[1][0].to(DEVICE)\n",
    "            anw = data[2][0].to(DEVICE)\n",
    "            trg = data[3][0].to(DEVICE)\n",
    "\n",
    "            if len(anw)==0:\n",
    "                continue\n",
    "\n",
    "            for index in anw:\n",
    "                output = model(src, index, max_len)\n",
    "\n",
    "                val_loss = criterion(output, trg[index])\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "            \n",
    "    # early_stop, consecutive_val_loss_increases = early_stop_1(val_losses, consecutive_val_loss_increases, max_consecutive_val_loss_increases)\n",
    "    early_stop, best_val_loss, consecutive_val_loss_increases = early_stop_2(avg_val_loss, best_val_loss, consecutive_val_loss_increases, max_consecutive_val_loss_increases)\n",
    "    if early_stop:\n",
    "        print(f'Epoch [{epoch+1}/{embedding_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f} \\nEarly Stop Triggered!')\n",
    "        torch.save(model, f'../데이터/Checkpoint/attention_tr_{train_ratio}_lr_{attention_lr}_wd_{attention_weight_decay}_batch_{attention_batch}_epochs_{epoch+1}_hdim_{attention_hidden_dim}_ws_{attention_window_size}.pth')\n",
    "        break\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{lstm_epochs}], Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}')\n",
    "\n",
    "plot_train_val_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../데이터/Checkpoint/embedding_tr_0.8_lr_1e-05_wd_0_batch_128_epochs_131_e1_128_e2_128_e3_512_emb_1024_d1512_d2_256_d3_128.pth')\n",
    "dataset = LSTM_Dataset(model, table_1, table_2, table_3, embedding_dim, transformer_window_size, DEVICE)\n",
    "\n",
    "dataset_length = len(dataset)\n",
    "split_point = int(train_ratio * len(dataset))\n",
    "train_indices = range(0, split_point)\n",
    "val_indices = range(split_point, dataset_length)\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=transformer_batch, shuffle=False, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=transformer_batch, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Train Loss: 1.7742, Val Loss: 1.3610\n",
      "Epoch [2/150], Train Loss: 1.0201, Val Loss: 1.1391\n",
      "Epoch [3/150], Train Loss: 0.9835, Val Loss: 1.1193\n",
      "Epoch [4/150], Train Loss: 0.9828, Val Loss: 1.1159\n",
      "Epoch [5/150], Train Loss: 0.9828, Val Loss: 1.1152\n",
      "Epoch [6/150], Train Loss: 0.9828, Val Loss: 1.1150\n",
      "Epoch [7/150], Train Loss: 0.9828, Val Loss: 1.1150\n",
      "Epoch [8/150], Train Loss: 0.9828, Val Loss: 1.1150\n",
      "Epoch [9/150], Train Loss: 0.9828, Val Loss: 1.1150\n",
      "Epoch [10/150], Train Loss: 0.9828, Val Loss: 1.1150\n",
      "Epoch [11/150], Train Loss: 0.9828, Val Loss: 1.1150\n",
      "Epoch [12/150], Train Loss: 0.9828, Val Loss: 1.1150\n",
      "Epoch [13/150], Train Loss: 0.9828, Val Loss: 1.1150\n",
      "Epoch [14/150], Train Loss: 0.9828, Val Loss: 1.1150\n",
      "Epoch [15/150], Train Loss: 0.9828, Val Loss: 1.1150\n",
      "Epoch [16/150], Train Loss: 0.9828, Val Loss: 1.1150\n",
      "Epoch [17/150], Train Loss: 0.9828, Val Loss: 1.1150\n",
      "Epoch [18/150], Train Loss: 0.9828, Val Loss: 1.1150\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(embedding_dim, transformer_window_size, 1, 2, 2).to(DEVICE)\n",
    "criterion = RMSE()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=transformer_lr, weight_decay=transformer_weight_decay)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "consecutive_val_loss_increases = 0\n",
    "max_consecutive_val_loss_increases = 3\n",
    "\n",
    "for epoch in range(transformer_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        src = data[0].to(DEVICE)\n",
    "        trg = data[1].to(DEVICE)\n",
    "\n",
    "        if (trg[0] != 0):\n",
    "            src_mask = model.generate_square_subsequent_mask(src.shape[1]).to(src.device)\n",
    "            output = model(src, src_mask)\n",
    "\n",
    "            train_loss = criterion(output[0], trg[0])\n",
    "            total_train_loss += train_loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            src = data[0].to(DEVICE)\n",
    "            trg = data[1].to(DEVICE)\n",
    "\n",
    "            if (trg[0] != 0):\n",
    "                src_mask = model.generate_square_subsequent_mask(src.shape[1]).to(src.device)\n",
    "                output = model(src, src_mask)\n",
    "\n",
    "                val_loss = criterion(output[0], trg[0])\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    early_stop, consecutive_val_loss_increases = early_stop_1(val_losses, consecutive_val_loss_increases, max_consecutive_val_loss_increases)\n",
    "    # early_stop, best_val_loss, consecutive_val_loss_increases = early_stop_2(avg_val_loss, best_val_loss, consecutive_val_loss_increases, max_consecutive_val_loss_increases)\n",
    "    if early_stop:\n",
    "        print(f'Epoch [{epoch+1}/{embedding_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f} \\nEarly Stop Triggered!')\n",
    "        torch.save(model, f'../데이터/Checkpoint/transformer_tr_{train_ratio}_lr_{transformer_lr}_wd_{transformer_weight_decay}_batch_{transformer_batch}_epochs_{epoch+1}_ws_{transformer_window_size}.pth')\n",
    "        break\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{lstm_epochs}], Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}')\n",
    "\n",
    "plot_train_val_losses(train_losses, val_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
