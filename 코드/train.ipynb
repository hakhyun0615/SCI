{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from Dataset.Economy_Dataset import EconomyDataset\n",
    "from Dataset.Transaction_Dataset import TransactionDataset\n",
    "\n",
    "from Model.LSTM import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5\n",
    "hidden_size = 256\n",
    "output_size = 1\n",
    "\n",
    "lr = 1e-3\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "economy_df = pd.read_excel('../데이터/Economy/economy_all.xlsx')\n",
    "economy_df = economy_df['국고채금리'].values\n",
    "transaction_df = pd.read_csv('../데이터/Transaction/transaction_final.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimhakhyun/Desktop/Git/sci/SCI/코드/Dataset/Economy_Dataset.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:248.)\n",
      "  self.x = torch.FloatTensor(X)\n"
     ]
    }
   ],
   "source": [
    "economy_train_size = int(len(economy_df)*0.6)\n",
    "economy_val_size = int(len(economy_df)*0.3)\n",
    "trainsaction_train_size = int(len(transaction_df)*0.6)\n",
    "trainsaction_val_size = int(len(transaction_df)*0.3)\n",
    "\n",
    "economy_train_dataset = EconomyDataset(economy_df[:economy_train_size])\n",
    "economy_train_loader = DataLoader(economy_train_dataset, batch_size=2)\n",
    "economy_val_dataset = EconomyDataset(economy_df[economy_train_size:economy_train_size+economy_val_size])\n",
    "economy_val_loader = DataLoader(economy_val_dataset, batch_size=2)\n",
    "economy_test_dataset = EconomyDataset(economy_df[economy_train_size+economy_val_size:])\n",
    "economy_test_loader = DataLoader(economy_test_dataset, batch_size=2)\n",
    "\n",
    "transaction_train_dataset = TransactionDataset(transaction_df[:trainsaction_train_size])\n",
    "transaction_train_loader = DataLoader(transaction_train_dataset, batch_size=2)\n",
    "transaction_val_dataset = TransactionDataset(transaction_df[trainsaction_train_size:trainsaction_train_size+trainsaction_val_size])\n",
    "transaction_val_loader = DataLoader(transaction_val_dataset, batch_size=2)\n",
    "transaction_test_dataset = TransactionDataset(transaction_df[trainsaction_train_size+trainsaction_val_size:])\n",
    "transaction_test_loader = DataLoader(transaction_test_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100, Training Loss: 0.584766149520874, Validation Loss: 1.7173492695604051\n",
      "Epoch 1/100, Training Loss: 0.029341816902160645, Validation Loss: 0.4915290773829578\n",
      "Epoch 2/100, Training Loss: 0.014836261048913002, Validation Loss: 0.673044593539089\n",
      "Epoch 3/100, Training Loss: 0.011310496367514133, Validation Loss: 0.7112700086685696\n",
      "Epoch 4/100, Training Loss: 0.00764611829072237, Validation Loss: 0.7607639563669052\n",
      "Epoch 5/100, Training Loss: 0.005434147082269192, Validation Loss: 0.8015894385586891\n",
      "Epoch 6/100, Training Loss: 0.0051312013529241085, Validation Loss: 0.8240756413766316\n",
      "Epoch 7/100, Training Loss: 0.005548834800720215, Validation Loss: 0.8355885456715312\n",
      "Epoch 8/100, Training Loss: 0.00619431771337986, Validation Loss: 0.8415670536591539\n",
      "Epoch 9/100, Training Loss: 0.006885802838951349, Validation Loss: 0.844067028391042\n",
      "Epoch 10/100, Training Loss: 0.0075322529301047325, Validation Loss: 0.8453299791019943\n",
      "Epoch 11/100, Training Loss: 0.008100266568362713, Validation Loss: 0.8443624642677605\n",
      "Epoch 12/100, Training Loss: 0.00857716053724289, Validation Loss: 0.842393031809479\n",
      "Epoch 13/100, Training Loss: 0.008959265425801277, Validation Loss: 0.83892971869292\n",
      "Epoch 14/100, Training Loss: 0.009255285374820232, Validation Loss: 0.8342103626179908\n",
      "Epoch 15/100, Training Loss: 0.009476643986999989, Validation Loss: 0.828186296192663\n",
      "Epoch 16/100, Training Loss: 0.009638863615691662, Validation Loss: 0.8209219521709851\n",
      "Epoch 17/100, Training Loss: 0.009755201637744904, Validation Loss: 0.8124867084303072\n",
      "Epoch 18/100, Training Loss: 0.00983947142958641, Validation Loss: 0.802844618447125\n",
      "Epoch 19/100, Training Loss: 0.009902267716825008, Validation Loss: 0.7920656908702638\n",
      "Epoch 20/100, Training Loss: 0.009953726083040237, Validation Loss: 0.780042652107243\n",
      "Epoch 21/100, Training Loss: 0.010000957176089287, Validation Loss: 0.7668131437551763\n",
      "Epoch 22/100, Training Loss: 0.010051335208117962, Validation Loss: 0.7522090746622\n",
      "Epoch 23/100, Training Loss: 0.010109065100550652, Validation Loss: 0.7362366866852555\n",
      "Epoch 24/100, Training Loss: 0.010180041193962097, Validation Loss: 0.7186880578353468\n",
      "Epoch 25/100, Training Loss: 0.010267031379044056, Validation Loss: 0.6995613683081631\n",
      "Epoch 26/100, Training Loss: 0.0103756133466959, Validation Loss: 0.6786751464741039\n",
      "Epoch 27/100, Training Loss: 0.01050804927945137, Validation Loss: 0.6560857342389811\n",
      "Epoch 28/100, Training Loss: 0.010669531300663948, Validation Loss: 0.6317678738518485\n",
      "Epoch 29/100, Training Loss: 0.010861445218324661, Validation Loss: 0.6059654083967742\n",
      "Epoch 30/100, Training Loss: 0.01108557265251875, Validation Loss: 0.578983433823201\n",
      "Epoch 31/100, Training Loss: 0.011336270719766617, Validation Loss: 0.5513864412330024\n",
      "Epoch 32/100, Training Loss: 0.011600208468735218, Validation Loss: 0.523851973422487\n",
      "Epoch 33/100, Training Loss: 0.011849584057927132, Validation Loss: 0.49718124667872743\n",
      "Epoch 34/100, Training Loss: 0.012045331299304962, Validation Loss: 0.47216527154003934\n",
      "Epoch 35/100, Training Loss: 0.012155107222497463, Validation Loss: 0.4495004728087224\n",
      "Epoch 36/100, Training Loss: 0.012203743681311607, Validation Loss: 0.4296825849284817\n",
      "Epoch 37/100, Training Loss: 0.012354274280369282, Validation Loss: 0.41294107128799495\n",
      "Epoch 38/100, Training Loss: 0.012939021922647953, Validation Loss: 0.3992476177850871\n",
      "Epoch 39/100, Training Loss: 0.014268896542489529, Validation Loss: 0.38832472728764905\n",
      "Epoch 40/100, Training Loss: 0.016171781346201897, Validation Loss: 0.3794257943934229\n",
      "Epoch 41/100, Training Loss: 0.01779109239578247, Validation Loss: 0.37115926232737756\n",
      "Epoch 42/100, Training Loss: 0.018297391012310982, Validation Loss: 0.36236073913044364\n",
      "Epoch 43/100, Training Loss: 0.01778344064950943, Validation Loss: 0.35313345542402075\n",
      "Epoch 44/100, Training Loss: 0.01697048917412758, Validation Loss: 0.34345195735555273\n",
      "Epoch 45/100, Training Loss: 0.016351493075489998, Validation Loss: 0.33259333305094124\n",
      "Epoch 46/100, Training Loss: 0.016160812228918076, Validation Loss: 0.32210507818464457\n",
      "Epoch 47/100, Training Loss: 0.01656467840075493, Validation Loss: 0.3138516948425344\n",
      "Epoch 48/100, Training Loss: 0.017611125484108925, Validation Loss: 0.30788037727221046\n",
      "Epoch 49/100, Training Loss: 0.019029829651117325, Validation Loss: 0.3041606275946833\n",
      "Epoch 50/100, Training Loss: 0.02024267427623272, Validation Loss: 0.30293439214749796\n",
      "Epoch 51/100, Training Loss: 0.02076978050172329, Validation Loss: 0.30358533017819617\n",
      "Epoch 52/100, Training Loss: 0.020562300458550453, Validation Loss: 0.3038439759277805\n",
      "Epoch 53/100, Training Loss: 0.0200125053524971, Validation Loss: 0.3016049316834791\n",
      "Epoch 54/100, Training Loss: 0.019637443125247955, Validation Loss: 0.29737297350740327\n",
      "Epoch 55/100, Training Loss: 0.019652962684631348, Validation Loss: 0.29312671101485777\n",
      "Epoch 56/100, Training Loss: 0.019937483593821526, Validation Loss: 0.29018719851280494\n",
      "Epoch 57/100, Training Loss: 0.02024749480187893, Validation Loss: 0.2888456844250738\n",
      "Epoch 58/100, Training Loss: 0.020393790677189827, Validation Loss: 0.28859357667222085\n",
      "Epoch 59/100, Training Loss: 0.020330533385276794, Validation Loss: 0.28845543836359866\n",
      "Epoch 60/100, Training Loss: 0.02014905773103237, Validation Loss: 0.2876097504766741\n",
      "Epoch 61/100, Training Loss: 0.019986042752861977, Validation Loss: 0.2859520299721875\n",
      "Epoch 62/100, Training Loss: 0.019918056204915047, Validation Loss: 0.28400814495086835\n",
      "Epoch 63/100, Training Loss: 0.01992940343916416, Validation Loss: 0.28239042623421745\n",
      "Epoch 64/100, Training Loss: 0.01995403692126274, Validation Loss: 0.2813727400695955\n",
      "Epoch 65/100, Training Loss: 0.01993441954255104, Validation Loss: 0.2808029445347659\n",
      "Epoch 66/100, Training Loss: 0.019856909289956093, Validation Loss: 0.28029632992547704\n",
      "Epoch 67/100, Training Loss: 0.019749488681554794, Validation Loss: 0.2795468580620114\n",
      "Epoch 68/100, Training Loss: 0.019652066752314568, Validation Loss: 0.2785302130100068\n",
      "Epoch 69/100, Training Loss: 0.019585447385907173, Validation Loss: 0.27745711947708124\n",
      "Epoch 70/100, Training Loss: 0.019542312249541283, Validation Loss: 0.2765634684131198\n",
      "Epoch 71/100, Training Loss: 0.019500181078910828, Validation Loss: 0.2759334913186779\n",
      "Epoch 72/100, Training Loss: 0.01944165863096714, Validation Loss: 0.27547278202525505\n",
      "Epoch 73/100, Training Loss: 0.019365541636943817, Validation Loss: 0.27501374206466217\n",
      "Epoch 74/100, Training Loss: 0.019284946843981743, Validation Loss: 0.27445657641302595\n",
      "Epoch 75/100, Training Loss: 0.019213801249861717, Validation Loss: 0.27383106687141534\n",
      "Epoch 76/100, Training Loss: 0.01915711537003517, Validation Loss: 0.2732483829292635\n",
      "Epoch 77/100, Training Loss: 0.019108839333057404, Validation Loss: 0.27279948763680295\n",
      "Epoch 78/100, Training Loss: 0.019059285521507263, Validation Loss: 0.2724886162749109\n",
      "Epoch 79/100, Training Loss: 0.019002996385097504, Validation Loss: 0.27224574453586164\n",
      "Epoch 80/100, Training Loss: 0.01894245855510235, Validation Loss: 0.27199482858590535\n",
      "Epoch 81/100, Training Loss: 0.018884781748056412, Validation Loss: 0.2717146172009442\n",
      "Epoch 82/100, Training Loss: 0.018835559487342834, Validation Loss: 0.27144658581060604\n",
      "Epoch 83/100, Training Loss: 0.018795059993863106, Validation Loss: 0.27125285941552385\n",
      "Epoch 84/100, Training Loss: 0.018758375197649002, Validation Loss: 0.27116132231042556\n",
      "Epoch 85/100, Training Loss: 0.01872073858976364, Validation Loss: 0.271150950352811\n",
      "Epoch 86/100, Training Loss: 0.018681427463889122, Validation Loss: 0.27117469969068353\n",
      "Epoch 87/100, Training Loss: 0.0186433307826519, Validation Loss: 0.27120172915497925\n",
      "Epoch 88/100, Training Loss: 0.018610995262861252, Validation Loss: 0.2712431451592628\n",
      "Epoch 89/100, Training Loss: 0.018586158752441406, Validation Loss: 0.27133502716086305\n",
      "Epoch 90/100, Training Loss: 0.018567262217402458, Validation Loss: 0.2715097669008953\n",
      "Epoch 91/100, Training Loss: 0.018550928682088852, Validation Loss: 0.27176890460915665\n",
      "Epoch 92/100, Training Loss: 0.018534965813159943, Validation Loss: 0.2720868973182015\n",
      "Epoch 93/100, Training Loss: 0.01852058619260788, Validation Loss: 0.27243731006456073\n",
      "Epoch 94/100, Training Loss: 0.018510224297642708, Validation Loss: 0.2728161461584802\n",
      "Epoch 95/100, Training Loss: 0.018506791442632675, Validation Loss: 0.27324443567652323\n",
      "Epoch 96/100, Training Loss: 0.018510276451706886, Validation Loss: 0.2737494652226035\n",
      "Epoch 97/100, Training Loss: 0.018518824130296707, Validation Loss: 0.2743432451076972\n",
      "Epoch 98/100, Training Loss: 0.01853056252002716, Validation Loss: 0.2750220635768658\n",
      "Epoch 99/100, Training Loss: 0.018544504418969154, Validation Loss: 0.27577173937087146\n",
      "Epoch 100/100, Training Loss: 0.018558399751782417, Validation Loss: 0.27656765180706444\n"
     ]
    }
   ],
   "source": [
    "# 경제 모델\n",
    "best_val_loss = float('inf') \n",
    "for epoch in range(num_epochs + 1):\n",
    "    model.train()\n",
    "    for batch_idx, samples in enumerate(economy_train_loader):\n",
    "        x_train, y_train = samples\n",
    "\n",
    "        prediction = model(x_train)\n",
    "        cost = criterion(prediction, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, samples in enumerate(economy_val_loader):\n",
    "            x_val, y_val = samples\n",
    "\n",
    "            prediction = model(x_val)\n",
    "            loss = criterion(prediction, y_val)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(economy_val_loader)\n",
    "    print(f'Epoch {epoch}/{num_epochs}, Training Loss: {cost.item()}, Validation Loss: {val_loss}')\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), '../코드/Checkpoint/best_economy_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100, Training Loss: 33377.578125, Validation Loss: 1967039.132540804\n",
      "Epoch 1/100, Training Loss: 5665.9248046875, Validation Loss: 1882858.0450580737\n",
      "Epoch 2/100, Training Loss: 24919.158203125, Validation Loss: 1940272.2353766398\n",
      "Epoch 3/100, Training Loss: 30888.0625, Validation Loss: 1971206.7120309365\n",
      "Epoch 4/100, Training Loss: 2348.486083984375, Validation Loss: 1856136.980657875\n",
      "Epoch 5/100, Training Loss: 10181.5048828125, Validation Loss: 1882740.2206111744\n",
      "Epoch 6/100, Training Loss: 1729.197265625, Validation Loss: 1853625.5410154085\n",
      "Epoch 7/100, Training Loss: 4140.4482421875, Validation Loss: 1899214.0614695866\n",
      "Epoch 8/100, Training Loss: 489.42919921875, Validation Loss: 1836349.1128731049\n",
      "Epoch 9/100, Training Loss: 9324.7646484375, Validation Loss: 1910136.5383456098\n",
      "Epoch 10/100, Training Loss: 1299.746826171875, Validation Loss: 1816424.7702547533\n",
      "Epoch 11/100, Training Loss: 260.2991638183594, Validation Loss: 1845351.6620287467\n",
      "Epoch 12/100, Training Loss: 662.641357421875, Validation Loss: 1888075.1473737222\n",
      "Epoch 13/100, Training Loss: 1377.7943115234375, Validation Loss: 1847694.7875008574\n",
      "Epoch 14/100, Training Loss: 550.8510131835938, Validation Loss: 1876543.1220870723\n",
      "Epoch 15/100, Training Loss: 942.0223388671875, Validation Loss: 1837680.4716922196\n",
      "Epoch 16/100, Training Loss: 1843.9224853515625, Validation Loss: 1815249.3406435915\n",
      "Epoch 17/100, Training Loss: 1112.066162109375, Validation Loss: 1865021.114379758\n",
      "Epoch 18/100, Training Loss: 24.103641510009766, Validation Loss: 1840563.1619841394\n",
      "Epoch 19/100, Training Loss: 717.0326538085938, Validation Loss: 1845845.543157415\n",
      "Epoch 20/100, Training Loss: 324.8706970214844, Validation Loss: 1848495.732843443\n",
      "Epoch 21/100, Training Loss: 350.8761901855469, Validation Loss: 1850450.8162544293\n",
      "Epoch 22/100, Training Loss: 174.9742431640625, Validation Loss: 1846666.7566390834\n",
      "Epoch 23/100, Training Loss: 330.31463623046875, Validation Loss: 1846288.2015293776\n",
      "Epoch 24/100, Training Loss: 747.4804077148438, Validation Loss: 1853736.4875093196\n",
      "Epoch 25/100, Training Loss: 254.31527709960938, Validation Loss: 1836686.471448922\n",
      "Epoch 26/100, Training Loss: 273.3952331542969, Validation Loss: 1834269.0066380745\n",
      "Epoch 27/100, Training Loss: 1536.6744384765625, Validation Loss: 1842478.8823032207\n",
      "Epoch 28/100, Training Loss: 1958.49462890625, Validation Loss: 1855307.493030632\n",
      "Epoch 29/100, Training Loss: 8.749810218811035, Validation Loss: 1809133.4899899832\n",
      "Epoch 30/100, Training Loss: 4412.48193359375, Validation Loss: 1859473.1912168313\n",
      "Epoch 31/100, Training Loss: 69.74452209472656, Validation Loss: 1809903.588784207\n",
      "Epoch 32/100, Training Loss: 42.67795944213867, Validation Loss: 1807784.5287366067\n",
      "Epoch 33/100, Training Loss: 72.90933227539062, Validation Loss: 1810440.2266483041\n",
      "Epoch 34/100, Training Loss: 766.7734375, Validation Loss: 1780389.2934860452\n",
      "Epoch 35/100, Training Loss: 53.72646713256836, Validation Loss: 1802788.9244249368\n",
      "Epoch 36/100, Training Loss: 418.81982421875, Validation Loss: 1787651.233148912\n",
      "Epoch 37/100, Training Loss: 52.38211441040039, Validation Loss: 1813033.927950408\n",
      "Epoch 38/100, Training Loss: 66.4925537109375, Validation Loss: 1794620.8176361877\n",
      "Epoch 39/100, Training Loss: 110.208984375, Validation Loss: 1792658.6445943767\n",
      "Epoch 40/100, Training Loss: 132.755859375, Validation Loss: 1791029.4202542424\n",
      "Epoch 41/100, Training Loss: 177.6519317626953, Validation Loss: 1768890.0918829201\n",
      "Epoch 42/100, Training Loss: 1014.5997924804688, Validation Loss: 1800812.7165699033\n",
      "Epoch 43/100, Training Loss: 649.1671752929688, Validation Loss: 1818613.6083220385\n",
      "Epoch 44/100, Training Loss: 473.40240478515625, Validation Loss: 1817324.6191035968\n",
      "Epoch 45/100, Training Loss: 269.58978271484375, Validation Loss: 1813060.1585957776\n",
      "Epoch 46/100, Training Loss: 219.092041015625, Validation Loss: 1813959.3709976664\n",
      "Epoch 47/100, Training Loss: 1958.99169921875, Validation Loss: 1822831.7358794897\n",
      "Epoch 48/100, Training Loss: 2130.872802734375, Validation Loss: 1822370.5358465854\n",
      "Epoch 49/100, Training Loss: 1311.7447509765625, Validation Loss: 1818554.6514065599\n",
      "Epoch 50/100, Training Loss: 21.660207748413086, Validation Loss: 1799997.3628638366\n",
      "Epoch 51/100, Training Loss: 9.270806312561035, Validation Loss: 1796752.9136866604\n",
      "Epoch 52/100, Training Loss: 114.22526550292969, Validation Loss: 1803584.5237844568\n",
      "Epoch 53/100, Training Loss: 241.34107971191406, Validation Loss: 1806328.0254318896\n",
      "Epoch 54/100, Training Loss: 75.30731201171875, Validation Loss: 1802804.2413782182\n",
      "Epoch 55/100, Training Loss: 125.72891235351562, Validation Loss: 1804217.8442662354\n",
      "Epoch 56/100, Training Loss: 137.578125, Validation Loss: 1805405.969330749\n",
      "Epoch 57/100, Training Loss: 109.68675994873047, Validation Loss: 1804881.555972246\n",
      "Epoch 58/100, Training Loss: 32.222808837890625, Validation Loss: 1801236.1198432564\n",
      "Epoch 59/100, Training Loss: 10487.7900390625, Validation Loss: 1885694.7759408434\n",
      "Epoch 60/100, Training Loss: 98.4314956665039, Validation Loss: 1802505.5165069422\n",
      "Epoch 61/100, Training Loss: 137.6439971923828, Validation Loss: 1804675.91035632\n",
      "Epoch 62/100, Training Loss: 83.66710662841797, Validation Loss: 1803442.9510411248\n",
      "Epoch 63/100, Training Loss: 1038.6693115234375, Validation Loss: 1824546.2049074278\n",
      "Epoch 64/100, Training Loss: 0.4169955849647522, Validation Loss: 1812098.0003199393\n",
      "Epoch 65/100, Training Loss: 13.1370849609375, Validation Loss: 1797526.7769152492\n",
      "Epoch 66/100, Training Loss: 1307.0802001953125, Validation Loss: 1768352.2395327615\n"
     ]
    }
   ],
   "source": [
    "# 부동산 모델\n",
    "best_val_loss = float('inf') \n",
    "for epoch in range(num_epochs + 1):\n",
    "    model.train()\n",
    "    for batch_idx, samples in enumerate(transaction_train_loader):\n",
    "        x_train, y_train = samples\n",
    "\n",
    "        prediction = model(x_train)\n",
    "        cost = criterion(prediction, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, samples in enumerate(transaction_val_loader):\n",
    "            x_val, y_val = samples\n",
    "\n",
    "            prediction = model(x_val)\n",
    "            loss = criterion(prediction, y_val)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(transaction_val_loader)\n",
    "    print(f'Epoch {epoch}/{num_epochs}, Training Loss: {cost.item()}, Validation Loss: {val_loss}')\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), '../코드/Checkpoint/best_transaction_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
