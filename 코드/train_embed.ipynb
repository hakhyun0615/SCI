{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from Dataset.emb_auto import AutoDataset\n",
    "from Model.AE import Auto\n",
    "\n",
    "import utils\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 다운 & 전처리\n",
    "\n",
    "df = pd.read_feather('../데이터/기본데이터.feather')\n",
    "\n",
    "try: del df['Unnamed: 0']\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[0] = df['0'].apply(utils.to_list)\n",
    "# df[1] = df['1'].apply(utils.to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0] = df['0']\n",
    "df[1] = df['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\sci\\SCI\\코드\\Dataset\\emb_auto.py:16: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xe . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  self.x = torch.FloatTensor(X)\n"
     ]
    }
   ],
   "source": [
    "len_df = len(df)\n",
    "train_len = int(len_df *0.6)\n",
    "val_len = int(len_df * 0.3)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = AutoDataset(df[:train_len])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "val_dataset = AutoDataset(df[train_len:train_len+val_len])\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "test_dataset = AutoDataset(df[train_len+val_len:])\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 크기 : torch.Size([64, 7])\n",
      "Y 크기 : torch.Size([64, 7])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_loader:\n",
    "  print(\"X 크기 : {}\".format(x.shape))\n",
    "  print(\"Y 크기 : {}\".format(y.shape))\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 7\n",
    "Model = Auto(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available\n",
      "작동하는지 실험\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 0.0000, 0.0139, 0.1232, 0.0735, 0.0148, 0.0000, 0.0000, 0.0000,\n",
       "          0.0792, 0.0000, 0.0000, 0.0000, 0.0000, 0.0888, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0149, 0.0047, 0.0754, 0.0000, 0.0100, 0.0000,\n",
       "          0.0403, 0.1067, 0.0460, 0.0000, 0.1756, 0.0027, 0.0000, 0.1208, 0.0000,\n",
       "          0.0000, 0.0273, 0.0000, 0.1229, 0.0759, 0.1164, 0.0000, 0.1078, 0.0137,\n",
       "          0.0797, 0.0000, 0.0133, 0.0000, 0.0250, 0.0000, 0.0000, 0.0017, 0.1379,\n",
       "          0.0570, 0.0000, 0.0685, 0.0380, 0.0480, 0.1049, 0.0077, 0.0000, 0.0000,\n",
       "          0.0000, 0.0124, 0.0000, 0.0000, 0.0000, 0.0000, 0.1355, 0.0000, 0.0228,\n",
       "          0.0149, 0.0542, 0.1049, 0.0000, 0.0883, 0.0000, 0.0476, 0.0000, 0.2082,\n",
       "          0.0043, 0.0000, 0.0000, 0.0951, 0.1261, 0.0782, 0.0000, 0.0000, 0.1348,\n",
       "          0.2457, 0.0000, 0.0000, 0.0000, 0.0000, 0.1671, 0.0000, 0.1233, 0.1318,\n",
       "          0.0081, 0.0000, 0.1436, 0.0000, 0.1254, 0.1045, 0.0000, 0.0000, 0.0131,\n",
       "          0.0000, 0.0027, 0.0210, 0.1473, 0.0900, 0.0000, 0.0000, 0.0715, 0.0043,\n",
       "          0.0665, 0.0655, 0.0000, 0.0000, 0.0272, 0.1021, 0.0679, 0.0000, 0.0000,\n",
       "          0.1326, 0.0232, 0.0000, 0.0011, 0.0667, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0937, 0.0000, 0.0000, 0.0000, 0.0205, 0.0776, 0.1481, 0.1104,\n",
       "          0.0086, 0.0000, 0.0000, 0.0267, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0684, 0.1071, 0.0000, 0.1763, 0.0410, 0.1043, 0.1336, 0.0000,\n",
       "          0.0930, 0.2115, 0.0000, 0.0000, 0.0061, 0.0000, 0.0000, 0.0970, 0.0293,\n",
       "          0.0000, 0.0000, 0.0000, 0.2384, 0.1517, 0.0845, 0.0913, 0.0610, 0.0000,\n",
       "          0.0000, 0.0347, 0.0047, 0.1251, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0551, 0.0000, 0.1751, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0460, 0.0000, 0.0043, 0.0410, 0.0000, 0.0000,\n",
       "          0.0190, 0.0000, 0.1831, 0.0000, 0.0067, 0.0727, 0.0000, 0.0000, 0.0029,\n",
       "          0.0397, 0.0000, 0.0000, 0.0000, 0.0000, 0.0645, 0.0644, 0.0823, 0.1359,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0670, 0.1301, 0.0000, 0.0000,\n",
       "          0.1062, 0.0000, 0.0379, 0.1467, 0.0000, 0.0347, 0.0225, 0.0000, 0.0000,\n",
       "          0.0841, 0.0373, 0.0000, 0.0000, 0.0000, 0.0000, 0.1304, 0.0793, 0.1128,\n",
       "          0.0000, 0.0213, 0.1093, 0.0000]], grad_fn=<ReluBackward0>),\n",
       " tensor([[0.4703, 0.5145, 0.5227, 0.4944, 0.5054, 0.5027, 0.5207]],\n",
       "        grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 & 모델에 device 붙임!!!\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'{device} is available')\n",
    "\n",
    "model = Model.to(device)\n",
    "\n",
    "print('작동하는지 실험')\n",
    "basic_data = torch.rand((1,input_size))\n",
    "model(basic_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "lr = 1e-3\n",
    "num_epochs = 1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      "train\n"
     ]
    }
   ],
   "source": [
    "## 학습하는 코드를 짜봐!!!\n",
    "\n",
    "train_n = len(train_loader)\n",
    "val_n = len(val_loader)\n",
    "\n",
    "# print(train_loader)\n",
    "best_val_loss = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('epoch : {}'.format(epoch))\n",
    "    running_loss = 0.0\n",
    "    num = 0\n",
    "    print(\"train\")\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:  # dataloader 함수에 def __len__에 return 값만큼 반복함\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        vec, out = model(inputs)\n",
    "        loss = criterion(out, labels)\n",
    "\n",
    "        optimizer.zero_grad() #\n",
    "        loss.backward() # loss가 최소가 되게하는\n",
    "        optimizer.step() # 어떤 방법으로 learning rate를 움직일거이냐\n",
    "        running_loss += loss.item() # 한 배치의 loss 더해주고,\n",
    "\n",
    "\n",
    "    print(running_loss/train_n)\n",
    "\n",
    "    with torch.no_grad():\n",
    "            print(\"Calculating validation results...\")\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            for inputs, labels in val_loader:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    vec, outs = model(inputs)\n",
    "\n",
    "                    loss= criterion(outs, labels)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            avg_val_loss = val_loss/val_n\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    stop_counter = 0            \n",
    "                    torch.save(model.state_dict(), 'Checkpoint/embedding_best_model.pth')\n",
    "\n",
    "\n",
    "            # if val_acc > best_val_acc:\n",
    "            #     print(f\"New best model for val accuracy : {val_acc:4.2%}! saving the best model..\")\n",
    "            #     # torch.save(model.module.state_dict(), f\"{save_dir}/best.pth\")\n",
    "            #     best_val_acc = val_acc\n",
    "            # torch.save(model.module.state_dict(), f\"{save_dir}/last.pth\")\n",
    "            print(\"val\")\n",
    "            print(\n",
    "                f\"loss: {val_loss/val_n:4.8} || \"\n",
    "            )\n",
    "    print('======================================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 더미데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "model = model.requires_grad_(False)\n",
    "for i, (x,_) in enumerate(test_dataset):\n",
    "    data.append(str(model(x)[0].tolist()))\n",
    "    if i==100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).to_excel('../데이터/인베딩더미.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
